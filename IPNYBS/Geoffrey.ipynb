{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Feature Selection and Permutation Importance\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Classification Models (used in feature importance or metrics evaluation)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    make_scorer\n",
    ")\n",
    "\n",
    "# General Settings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train_data = pd.read_csv('C:/Users/Hp/Desktop/Capstone Project/Original data/train_features.csv')\n",
    "train_labels = pd.read_csv('C:/Users/Hp/Desktop/Capstone Project/Original data/train_labels.csv')\n",
    "test_data = pd.read_csv('C:/Users/Hp/Desktop/Capstone Project/Original data/test_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>...</th>\n",
       "      <th>rrelgimp_12</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>a21_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aanz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Almost every day</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>6.2 or 3 times a month</td>\n",
       "      <td>2.4 or more times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aard</td>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>3. Widowed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3. 7–9 years</td>\n",
       "      <td>1. 1 or 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>4.Once a week</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>3.2 or 3 times a week</td>\n",
       "      <td>3.2 or 3 times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid    age_03     urban_03  married_03  n_mar_03    edu_gru_03  \\\n",
       "0  aace       NaN          NaN         NaN       NaN           NaN   \n",
       "1  aanz       NaN          NaN         NaN       NaN           NaN   \n",
       "2  aape       NaN          NaN         NaN       NaN           NaN   \n",
       "3  aard  1. 50–59  1. 100,000+  3. Widowed       1.0  3. 7–9 years   \n",
       "4  ablr       NaN          NaN         NaN       NaN           NaN   \n",
       "\n",
       "  n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  ...  \\\n",
       "0               NaN           NaN          NaN           NaN  ...   \n",
       "1               NaN           NaN          NaN           NaN  ...   \n",
       "2               NaN           NaN          NaN           NaN  ...   \n",
       "3         1. 1 or 2           0.0      4. Fair           0.0  ...   \n",
       "4               NaN           NaN          NaN           NaN  ...   \n",
       "\n",
       "            rrelgimp_12            rrfcntx_m_12              rsocact_m_12  \\\n",
       "0  2.somewhat important                 9.Never                   9.Never   \n",
       "1      1.very important                 9.Never        1.Almost every day   \n",
       "2  2.somewhat important  6.2 or 3 times a month  2.4 or more times a week   \n",
       "3      1.very important           4.Once a week                   9.Never   \n",
       "4      1.very important   3.2 or 3 times a week     3.2 or 3 times a week   \n",
       "\n",
       "   rrelgwk_12  a16a_12  a21_12  a22_12  a33b_12  a34_12  \\\n",
       "0        0.No      NaN     NaN     NaN      NaN     NaN   \n",
       "1        0.No      NaN     NaN     NaN      NaN     NaN   \n",
       "2        0.No      NaN     NaN     NaN      NaN     NaN   \n",
       "3       1.Yes      NaN     NaN     NaN      NaN    No 2   \n",
       "4        0.No      NaN     NaN     NaN      NaN     NaN   \n",
       "\n",
       "                              j11_12  \n",
       "0                         Concrete 2  \n",
       "1                         Concrete 2  \n",
       "2  Wood, mosaic, or other covering 1  \n",
       "3                         Concrete 2  \n",
       "4  Wood, mosaic, or other covering 1  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>year</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>2021</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aanz</td>\n",
       "      <td>2021</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aape</td>\n",
       "      <td>2016</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aape</td>\n",
       "      <td>2021</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aard</td>\n",
       "      <td>2021</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  year  composite_score\n",
       "0  aace  2021              175\n",
       "1  aanz  2021              206\n",
       "2  aape  2016              161\n",
       "3  aape  2021              144\n",
       "4  aard  2021              104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>...</th>\n",
       "      <th>rrelgimp_12</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a16a_12</th>\n",
       "      <th>a21_12</th>\n",
       "      <th>a22_12</th>\n",
       "      <th>a33b_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abxu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aeol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afnb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>3.2 or 3 times a week</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ajfh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>5.4 or more times a month</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ajvq</td>\n",
       "      <td>2. 60–69</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>1. Married or in civil union</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4. 10+ years</td>\n",
       "      <td>1. 1 or 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>1.Almost every day</td>\n",
       "      <td>4.Once a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid    age_03     urban_03                    married_03  n_mar_03  \\\n",
       "0  abxu       NaN          NaN                           NaN       NaN   \n",
       "1  aeol       NaN          NaN                           NaN       NaN   \n",
       "2  afnb       NaN          NaN                           NaN       NaN   \n",
       "3  ajfh       NaN          NaN                           NaN       NaN   \n",
       "4  ajvq  2. 60–69  1. 100,000+  1. Married or in civil union       1.0   \n",
       "\n",
       "     edu_gru_03 n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  \\\n",
       "0           NaN               NaN           NaN          NaN           NaN   \n",
       "1           NaN               NaN           NaN          NaN           NaN   \n",
       "2           NaN               NaN           NaN          NaN           NaN   \n",
       "3           NaN               NaN           NaN          NaN           NaN   \n",
       "4  4. 10+ years         1. 1 or 2           0.0          NaN           NaN   \n",
       "\n",
       "   ...           rrelgimp_12        rrfcntx_m_12               rsocact_m_12  \\\n",
       "0  ...                   NaN                 NaN                        NaN   \n",
       "1  ...      1.very important             9.Never                    9.Never   \n",
       "2  ...      1.very important             9.Never      3.2 or 3 times a week   \n",
       "3  ...  2.somewhat important             9.Never  5.4 or more times a month   \n",
       "4  ...  2.somewhat important  1.Almost every day              4.Once a week   \n",
       "\n",
       "   rrelgwk_12  a16a_12  a21_12  a22_12  a33b_12  a34_12  \\\n",
       "0         NaN      NaN     NaN     NaN      NaN     NaN   \n",
       "1       1.Yes      NaN     NaN     NaN      NaN     NaN   \n",
       "2       1.Yes      NaN     NaN     NaN      NaN     NaN   \n",
       "3        0.No      NaN     NaN     NaN      NaN     NaN   \n",
       "4        0.No      NaN     NaN     NaN      NaN    No 2   \n",
       "\n",
       "                              j11_12  \n",
       "0  Wood, mosaic, or other covering 1  \n",
       "1                         Concrete 2  \n",
       "2  Wood, mosaic, or other covering 1  \n",
       "3  Wood, mosaic, or other covering 1  \n",
       "4  Wood, mosaic, or other covering 1  \n",
       "\n",
       "[5 rows x 184 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3276, 184)\n",
      "(4343, 3)\n",
      "(819, 184)\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the 'uid' column in each dataframe\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape after merging: (5162, 186)\n",
      "    uid    age_03     urban_03  married_03  n_mar_03    edu_gru_03  \\\n",
      "0  aace       NaN          NaN         NaN       NaN           NaN   \n",
      "1  aanz       NaN          NaN         NaN       NaN           NaN   \n",
      "2  aape       NaN          NaN         NaN       NaN           NaN   \n",
      "3  aape       NaN          NaN         NaN       NaN           NaN   \n",
      "4  aard  1. 50–59  1. 100,000+  3. Widowed       1.0  3. 7–9 years   \n",
      "\n",
      "  n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  ...  \\\n",
      "0               NaN           NaN          NaN           NaN  ...   \n",
      "1               NaN           NaN          NaN           NaN  ...   \n",
      "2               NaN           NaN          NaN           NaN  ...   \n",
      "3               NaN           NaN          NaN           NaN  ...   \n",
      "4         1. 1 or 2           0.0      4. Fair           0.0  ...   \n",
      "\n",
      "               rsocact_m_12  rrelgwk_12  a16a_12  a21_12  a22_12  a33b_12  \\\n",
      "0                   9.Never        0.No      NaN     NaN     NaN      NaN   \n",
      "1        1.Almost every day        0.No      NaN     NaN     NaN      NaN   \n",
      "2  2.4 or more times a week        0.No      NaN     NaN     NaN      NaN   \n",
      "3  2.4 or more times a week        0.No      NaN     NaN     NaN      NaN   \n",
      "4                   9.Never       1.Yes      NaN     NaN     NaN      NaN   \n",
      "\n",
      "   a34_12                             j11_12    year  composite_score  \n",
      "0     NaN                         Concrete 2  2021.0            175.0  \n",
      "1     NaN                         Concrete 2  2021.0            206.0  \n",
      "2     NaN  Wood, mosaic, or other covering 1  2016.0            161.0  \n",
      "3     NaN  Wood, mosaic, or other covering 1  2021.0            144.0  \n",
      "4    No 2                         Concrete 2  2021.0            104.0  \n",
      "\n",
      "[5 rows x 186 columns]\n"
     ]
    }
   ],
   "source": [
    "# This will add labels only for rows in the training data\n",
    "combined_data = pd.merge(combined_data, train_labels, on='uid', how='left')\n",
    "\n",
    "# Check the shape and a few rows to confirm\n",
    "print(\"Combined data shape after merging:\", combined_data.shape)\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    uid  age_03  urban_03  married_03  edu_gru_03  n_living_child_03  \\\n",
      "0  aace     NaN       NaN         NaN         NaN                NaN   \n",
      "1  aanz     NaN       NaN         NaN         NaN                NaN   \n",
      "2  aape     NaN       NaN         NaN         NaN                NaN   \n",
      "3  aape     NaN       NaN         NaN         NaN                NaN   \n",
      "4  aard     1.0       1.0         3.0         3.0                1.0   \n",
      "5  ablr     NaN       NaN         NaN         NaN                NaN   \n",
      "6  abme     1.0       0.0         1.0         1.0                3.0   \n",
      "7  abrn     1.0       0.0         1.0         0.0                3.0   \n",
      "8  acet     1.0       1.0         1.0         3.0                0.0   \n",
      "9  acgx     NaN       NaN         NaN         NaN                NaN   \n",
      "\n",
      "   glob_hlth_03  bmi_03  decis_famil_03  employment_03  ...  rjlocc_m_12  \\\n",
      "0           NaN     NaN             NaN            NaN  ...          6.0   \n",
      "1           NaN     NaN             NaN            NaN  ...         18.0   \n",
      "2           NaN     NaN             NaN            NaN  ...          NaN   \n",
      "3           NaN     NaN             NaN            NaN  ...          NaN   \n",
      "4           4.0     3.0             NaN            3.0  ...          NaN   \n",
      "5           NaN     NaN             NaN            NaN  ...          8.0   \n",
      "6           4.0     4.0             2.0            1.0  ...          6.0   \n",
      "7           4.0     4.0             1.0            1.0  ...         14.0   \n",
      "8           4.0     NaN             1.0            1.0  ...         17.0   \n",
      "9           NaN     NaN             NaN            NaN  ...          6.0   \n",
      "\n",
      "   rjobend_reason_12  rrelgimp_12  rrfcntx_m_12  rsocact_m_12  rrelgwk_12  \\\n",
      "0                NaN          2.0           9.0           9.0         0.0   \n",
      "1                NaN          1.0           9.0           1.0         0.0   \n",
      "2                NaN          2.0           6.0           2.0         0.0   \n",
      "3                NaN          2.0           6.0           2.0         0.0   \n",
      "4                NaN          1.0           4.0           9.0         1.0   \n",
      "5                NaN          1.0           3.0           3.0         0.0   \n",
      "6                NaN          1.0           9.0           9.0         0.0   \n",
      "7                NaN          2.0           8.0           9.0         0.0   \n",
      "8                NaN          2.0           1.0           1.0         0.0   \n",
      "9                NaN          1.0           3.0           4.0         0.0   \n",
      "\n",
      "   a22_12  a33b_12  a34_12  j11_12  \n",
      "0     NaN      NaN     NaN     2.0  \n",
      "1     NaN      NaN     NaN     2.0  \n",
      "2     NaN      NaN     NaN     1.0  \n",
      "3     NaN      NaN     NaN     1.0  \n",
      "4     NaN      NaN     2.0     2.0  \n",
      "5     NaN      NaN     NaN     1.0  \n",
      "6     NaN      NaN     2.0     2.0  \n",
      "7     NaN      NaN     2.0     2.0  \n",
      "8     NaN      NaN     2.0     2.0  \n",
      "9     NaN      NaN     NaN     2.0  \n",
      "\n",
      "[10 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "def extract_numeric(data, columns, position='first'):\n",
    "    \"\"\"Extract numeric values from specified columns of a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame to clean.\n",
    "        columns (list): List of column names to clean.\n",
    "        position (str): 'first' to extract the first numeric value, 'last' for the last.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        # Checking for numeric content\n",
    "        if combined_data[col].str.contains(r'\\d').any():  # Check if there's at least one numeric character\n",
    "            if position == 'first':\n",
    "                # Extracting the first numeric part using regex\n",
    "                combined_data[col] = combined_data[col].astype(str).str.extract(r'(\\d+)')[0]\n",
    "            elif position == 'last':\n",
    "                # Extracting the last numeric part using regex\n",
    "                combined_data[col] = combined_data[col].astype(str).str.extract(r'(\\d+)(?!.*\\d)')[0]\n",
    "            # Converting to float\n",
    "            combined_data[col] = combined_data[col].astype(float)\n",
    "\n",
    "# Selecting all object-type columns for cleaning\n",
    "columns_to_clean = combined_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Extracting numeric values based on the specified position ('first' or 'last')\n",
    "extract_numeric(combined_data, columns_to_clean, position='first')  # Change to 'last' if needed\n",
    "\n",
    "# Displaying the cleaned columns\n",
    "print(combined_data[columns_to_clean].head(10))  # Printing the first few rows of the cleaned columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aace', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 4.0, 0.0, nan, nan, nan, nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 2.0, 66.0, 6.0, nan, nan, 0.0, 0.0, 140000.0, 10000.0, 0.0, 0.0, 10000.0, 0.0, 0.0, 2.0, 9.0, 9.0, 0.0, nan, nan, nan, nan, nan, 2.0, 2021.0, 175.0], ['aanz', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, nan, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 2.0, 72.0, 18.0, nan, nan, 70000.0, 0.0, 70000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 1.0, 0.0, nan, nan, nan, nan, nan, 2.0, 2021.0, 206.0], ['aape', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 2.0, 0.0, nan, nan, nan, nan, nan, 1.0, 2016.0, 161.0], ['aape', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, nan, nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 6.0, 2.0, 0.0, nan, nan, nan, nan, nan, 1.0, 2021.0, 144.0], ['aard', 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 6.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, nan, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, nan, nan, nan, 2003.0, 4.0, 0.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 1.0, nan, nan, nan, nan, nan, 0.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, nan, 1.0, 4.0, 9.0, 1.0, nan, nan, nan, nan, 2.0, 2.0, 2021.0, 104.0], ['ablr', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 2.0, 60.0, 8.0, nan, nan, 10000.0, 0.0, 10000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, nan, nan, nan, nan, nan, 1.0, 2021.0, 183.0], ['abme', 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 30.0, nan, nan, nan, 0.0, 0.0, 70000.0, 70000.0, 0.0, 0.0, 70000.0, 0.0, 0.0, 1.0, 2.0, nan, 6.0, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 9.0, 0.0, nan, nan, nan, nan, 2.0, 2.0, 2021.0, 106.0], ['abrn', 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, nan, nan, nan, nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 48.0, 6.0, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, nan, 14.0, nan, nan, 30000.0, 0.0, 30000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 9.0, 0.0, nan, nan, nan, nan, 2.0, 2.0, 2021.0, 144.0], ['acet', 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, nan, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 35.0, nan, nan, nan, 30000.0, 0.0, 70000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 38000.0, 2.0, 1.0, 35.0, 17.0, nan, nan, 50000.0, 0.0, 80000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 30000.0, 2.0, 1.0, 1.0, 0.0, nan, nan, nan, nan, 2.0, 2.0, 2021.0, 152.0], ['acgx', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 2.0, 24.0, 6.0, nan, nan, 20000.0, 0.0, -30000.0, 0.0, -60000.0, 0.0, -60000.0, 0.0, 0.0, 1.0, 3.0, 4.0, 0.0, nan, nan, nan, nan, nan, 2.0, 2021.0, 144.0]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 rows of combined_data as a list of lists\n",
    "print(combined_data.head(10).values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5162, 186)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_data = combined_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary of feature categories\n",
    "feature_groups = {\n",
    "    'categorical_nominal': [\n",
    "        'ragender',  # Gender\n",
    "        'sgender_03', 'sgender_12',  # Spouse gender\n",
    "        'urban_03', 'urban_12',  # Rural/Urban\n",
    "        'married_03', 'married_12',  # Marital status\n",
    "        'rjlocc_m_03', 'rjlocc_m_12',  # Occupation category\n",
    "        'rjobend_reason_03', 'rjobend_reason_12',  # Job end reason\n",
    "        'a22_12',  # US job type\n",
    "        'a33b_12',  # US residency status\n",
    "        'j11_12',  # Floor material\n",
    "    ],\n",
    "    \n",
    "    'categorical_ordinal': [\n",
    "        'age_03', 'age_12',  # Age groups\n",
    "        'edu_gru_03', 'edu_gru_12',  # Education level\n",
    "        'n_living_child_03', 'n_living_child_12',  # Number of children\n",
    "        'glob_hlth_03', 'glob_hlth_12',  # Self-reported health\n",
    "        'bmi_03', 'bmi_12',  # BMI categories\n",
    "        'decis_famil_03', 'decis_famil_12',  # Family decision weight\n",
    "        'decis_personal_03', 'decis_personal_12',  # Personal decision weight\n",
    "        'employment_03', 'employment_12',  # Employment status\n",
    "        'rameduc_m', 'rafeduc_m',  # Parents' education\n",
    "        'rrelgimp_03', 'rrelgimp_12',  # Religion importance\n",
    "        'rrfcntx_m_12',  # Friend contact frequency\n",
    "        'rsocact_m_12',  # Social activity frequency\n",
    "        'rrelgwk_12',  # Religious service participation\n",
    "        'a34_12',  # English proficiency\n",
    "        'memory_12',  # Self-reported memory\n",
    "        'satis_ideal_12', 'satis_excel_12', 'satis_fine_12',\n",
    "        'cosas_imp_12', 'wouldnt_change_12'  # Life satisfaction measures\n",
    "    ],\n",
    "    \n",
    "    'binary_indicators': [\n",
    "        'migration_03', 'migration_12',  # US migration\n",
    "        'adl_dress_03', 'adl_dress_12',  # ADL limitations\n",
    "        'adl_walk_03', 'adl_walk_12',\n",
    "        'adl_bath_03', 'adl_bath_12',\n",
    "        'adl_eat_03', 'adl_eat_12',\n",
    "        'adl_bed_03', 'adl_bed_12',\n",
    "        'adl_toilet_03', 'adl_toilet_12',\n",
    "        'iadl_money_03', 'iadl_money_12',  # IADL limitations\n",
    "        'iadl_meds_03', 'iadl_meds_12',\n",
    "        'iadl_shop_03', 'iadl_shop_12',\n",
    "        'iadl_meals_03', 'iadl_meals_12',\n",
    "        'depressed_03', 'depressed_12',  # Mental health indicators\n",
    "        'hard_03', 'hard_12',\n",
    "        'restless_03', 'restless_12',\n",
    "        'happy_03', 'happy_12',\n",
    "        'lonely_03', 'lonely_12',\n",
    "        'enjoy_03', 'enjoy_12',\n",
    "        'sad_03', 'sad_12',\n",
    "        'tired_03', 'tired_12',\n",
    "        'energetic_03', 'energetic_12',\n",
    "        'cesd_depressed_03', 'cesd_depressed_12',\n",
    "        # Health conditions\n",
    "        'hypertension_03', 'hypertension_12',\n",
    "        'diabetes_03', 'diabetes_12',\n",
    "        'resp_ill_03', 'resp_ill_12',\n",
    "        'arthritis_03', 'arthritis_12',\n",
    "        'hrt_attack_03', 'hrt_attack_12',\n",
    "        'stroke_03', 'stroke_12',\n",
    "        'cancer_03', 'cancer_12',\n",
    "        # Health behaviors\n",
    "        'exer_3xwk_03', 'exer_3xwk_12',\n",
    "        'alcohol_03', 'alcohol_12',\n",
    "        'tobacco_03', 'tobacco_12',\n",
    "        # Healthcare utilization\n",
    "        'test_chol_03', 'test_chol_12',\n",
    "        'test_tuber_03', 'test_tuber_12',\n",
    "        'test_diab_03', 'test_diab_12',\n",
    "        'test_pres_03', 'test_pres_12',\n",
    "        'hosp_03', 'hosp_12',\n",
    "        'visit_med_03', 'visit_med_12',\n",
    "        'out_proc_03', 'out_proc_12',\n",
    "        'visit_dental_03', 'visit_dental_12',\n",
    "        # Insurance coverage\n",
    "        'imss_03', 'imss_12',\n",
    "        'issste_03', 'issste_12',\n",
    "        'pem_def_mar_03', 'pem_def_mar_12',\n",
    "        'insur_private_03', 'insur_private_12',\n",
    "        'insur_other_03', 'insur_other_12',\n",
    "        'seg_pop_12',\n",
    "        'insured_03', 'insured_12',\n",
    "        # Activities\n",
    "        'care_adult_12', 'care_child_12',\n",
    "        'volunteer_12', 'attends_class_12',\n",
    "        'attends_club_12', 'reads_12',\n",
    "        'games_12', 'table_games_12',\n",
    "        'comms_tel_comp_12', 'act_mant_12',\n",
    "        'tv_12', 'sewing_12'\n",
    "    ],\n",
    "    \n",
    "    'numerical_continuous': [\n",
    "        'n_mar_03', 'n_mar_12',  # Number of marriages\n",
    "        'n_adl_03', 'n_adl_12',  # Number of ADL limitations\n",
    "        'n_iadl_03', 'n_iadl_12',  # Number of IADL limitations\n",
    "        'n_depr_03', 'n_depr_12',  # Number of depression symptoms\n",
    "        'n_illnesses_03', 'n_illnesses_12',  # Number of illnesses\n",
    "        'rjob_hrswk_03', 'rjob_hrswk_12',  # Working hours\n",
    "        'rjob_end_03', 'rjob_end_12',  # Job end year\n",
    "        # Income and earnings\n",
    "        'rearnings_03', 'rearnings_12',\n",
    "        'searnings_03', 'searnings_12',\n",
    "        'hincome_03', 'hincome_12',\n",
    "        'hinc_business_03', 'hinc_business_12',\n",
    "        'hinc_rent_03', 'hinc_rent_12',\n",
    "        'hinc_assets_03', 'hinc_assets_12',\n",
    "        'hinc_cap_03', 'hinc_cap_12',\n",
    "        'rinc_pension_03', 'rinc_pension_12',\n",
    "        'sinc_pension_03', 'sinc_pension_12',\n",
    "        'a16a_12',  # Year first left for US\n",
    "        'a21_12'  # Total years in US\n",
    "    ],\n",
    "    \n",
    "    'identifier': ['uid']  # Unique identifier\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns with more than 40% missing values: ['bmi_03', 'decis_famil_03', 'sgender_03', 'rjob_hrswk_03', 'rjlocc_m_03', 'rjob_end_03', 'rjobend_reason_03', 'searnings_03', 'sinc_pension_03', 'rjob_hrswk_12', 'rjlocc_m_12', 'rjob_end_12', 'rjobend_reason_12', 'a16a_12', 'a21_12', 'a22_12', 'a33b_12']\n",
      "Remaining NaN values after filling: vax_flu_12         320\n",
      "vax_pneu_12        420\n",
      "rafeduc_m            1\n",
      "year               819\n",
      "composite_score    819\n",
      "dtype: int64\n",
      "    uid  age_03  urban_03  married_03  n_mar_03  edu_gru_03  \\\n",
      "0  aace     1.0       1.0         3.0  1.133275         3.0   \n",
      "1  aanz     1.0       1.0         3.0  1.133275         3.0   \n",
      "2  aape     1.0       1.0         3.0  1.133275         3.0   \n",
      "3  aape     1.0       1.0         3.0  1.133275         3.0   \n",
      "4  aard     1.0       1.0         3.0  1.000000         3.0   \n",
      "\n",
      "   n_living_child_03  migration_03  glob_hlth_03  adl_dress_03  ...  \\\n",
      "0                1.0           0.0           4.0           0.0  ...   \n",
      "1                1.0           0.0           4.0           0.0  ...   \n",
      "2                1.0           0.0           4.0           0.0  ...   \n",
      "3                1.0           0.0           4.0           0.0  ...   \n",
      "4                1.0           0.0           4.0           0.0  ...   \n",
      "\n",
      "   rinc_pension_12  sinc_pension_12  rrelgimp_12  rrfcntx_m_12  rsocact_m_12  \\\n",
      "0              0.0         0.000000          2.0           9.0           9.0   \n",
      "1              0.0         0.000000          1.0           9.0           1.0   \n",
      "2              0.0         0.000000          2.0           6.0           2.0   \n",
      "3              0.0         0.000000          2.0           6.0           2.0   \n",
      "4              0.0     11946.026987          1.0           4.0           9.0   \n",
      "\n",
      "   rrelgwk_12  a34_12  j11_12    year  composite_score  \n",
      "0         0.0     2.0     2.0  2021.0            175.0  \n",
      "1         0.0     2.0     2.0  2021.0            206.0  \n",
      "2         0.0     2.0     1.0  2016.0            161.0  \n",
      "3         0.0     2.0     1.0  2021.0            144.0  \n",
      "4         1.0     2.0     2.0  2021.0            104.0  \n",
      "\n",
      "[5 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the DataFrame to avoid modifying the original data\n",
    "combined_data_cleaned = combined_data.copy()\n",
    "\n",
    "# Calculate the threshold for dropping features\n",
    "threshold = 0.4 * len(combined_data_cleaned)  # 40% of the total rows\n",
    "\n",
    "# Identify columns to drop (those with more than 40% missing values)\n",
    "cols_to_drop = combined_data_cleaned.columns[combined_data_cleaned.isnull().sum() > threshold]\n",
    "\n",
    "# Drop the identified columns\n",
    "combined_data_cleaned.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# Print the columns that were dropped\n",
    "print(\"Dropped columns with more than 40% missing values:\", cols_to_drop.tolist())\n",
    "\n",
    "# Handling NaN values based on variable types after dropping columns\n",
    "for col in combined_data_cleaned.columns:\n",
    "    if col in feature_groups['numerical_continuous']:\n",
    "        # Fill numerical variables with the mean\n",
    "        combined_data_cleaned[col].fillna(combined_data_cleaned[col].mean(), inplace=True)\n",
    "\n",
    "    elif col in feature_groups['categorical_ordinal'] or col in feature_groups['categorical_nominal']:\n",
    "        # For both ordinal and nominal variables, use backward fill\n",
    "        combined_data_cleaned[col].bfill(inplace=True)\n",
    "\n",
    "    elif col in feature_groups['binary_indicators']:\n",
    "        # For binary indicators, fill with the mode\n",
    "        combined_data_cleaned[col].fillna(combined_data_cleaned[col].mode()[0], inplace=True)\n",
    "\n",
    "# Optionally, check for remaining NaN values\n",
    "remaining_nans = combined_data_cleaned.isnull().sum()\n",
    "print(\"Remaining NaN values after filling:\", remaining_nans[remaining_nans > 0])  # Print remaining columns with NaN values\n",
    "\n",
    "# Display the cleaned data\n",
    "print(combined_data_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    uid  age_03  urban_03  married_03  n_mar_03  edu_gru_03  \\\n",
      "0  aace     1.0       1.0         3.0  1.133275         3.0   \n",
      "1  aanz     1.0       1.0         3.0  1.133275         3.0   \n",
      "2  aape     1.0       1.0         3.0  1.133275         3.0   \n",
      "3  aape     1.0       1.0         3.0  1.133275         3.0   \n",
      "4  aard     1.0       1.0         3.0  1.000000         3.0   \n",
      "5  ablr     1.0       0.0         1.0  1.133275         1.0   \n",
      "6  abme     1.0       0.0         1.0  1.000000         1.0   \n",
      "7  abrn     1.0       0.0         1.0  2.000000         0.0   \n",
      "8  acet     1.0       1.0         1.0  1.000000         3.0   \n",
      "9  acgx     3.0       0.0         1.0  1.133275         0.0   \n",
      "\n",
      "   n_living_child_03  migration_03  glob_hlth_03  adl_dress_03  ...  \\\n",
      "0                1.0           0.0           4.0           0.0  ...   \n",
      "1                1.0           0.0           4.0           0.0  ...   \n",
      "2                1.0           0.0           4.0           0.0  ...   \n",
      "3                1.0           0.0           4.0           0.0  ...   \n",
      "4                1.0           0.0           4.0           0.0  ...   \n",
      "5                3.0           0.0           4.0           0.0  ...   \n",
      "6                3.0           0.0           4.0           0.0  ...   \n",
      "7                3.0           0.0           4.0           0.0  ...   \n",
      "8                0.0           0.0           4.0           0.0  ...   \n",
      "9                2.0           0.0           5.0           0.0  ...   \n",
      "\n",
      "   rinc_pension_12  sinc_pension_12  rrelgimp_12  rrfcntx_m_12  rsocact_m_12  \\\n",
      "0              0.0         0.000000          2.0           9.0           9.0   \n",
      "1              0.0         0.000000          1.0           9.0           1.0   \n",
      "2              0.0         0.000000          2.0           6.0           2.0   \n",
      "3              0.0         0.000000          2.0           6.0           2.0   \n",
      "4              0.0     11946.026987          1.0           4.0           9.0   \n",
      "5              0.0         0.000000          1.0           3.0           3.0   \n",
      "6              0.0         0.000000          1.0           9.0           9.0   \n",
      "7              0.0         0.000000          2.0           8.0           9.0   \n",
      "8              0.0     30000.000000          2.0           1.0           1.0   \n",
      "9              0.0         0.000000          1.0           3.0           4.0   \n",
      "\n",
      "   rrelgwk_12  a34_12  j11_12    year  composite_score  \n",
      "0         0.0     2.0     2.0  2021.0            175.0  \n",
      "1         0.0     2.0     2.0  2021.0            206.0  \n",
      "2         0.0     2.0     1.0  2016.0            161.0  \n",
      "3         0.0     2.0     1.0  2021.0            144.0  \n",
      "4         1.0     2.0     2.0  2021.0            104.0  \n",
      "5         0.0     2.0     1.0  2021.0            183.0  \n",
      "6         0.0     2.0     2.0  2021.0            106.0  \n",
      "7         0.0     2.0     2.0  2021.0            144.0  \n",
      "8         0.0     2.0     2.0  2021.0            152.0  \n",
      "9         0.0     2.0     2.0  2021.0            144.0  \n",
      "\n",
      "[10 rows x 169 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data_cleaned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid                0\n",
      "decis_famil_12     0\n",
      "out_proc_12        0\n",
      "visit_dental_12    0\n",
      "imss_12            0\n",
      "                  ..\n",
      "employment_03      0\n",
      "age_12             0\n",
      "urban_12           0\n",
      "married_12         0\n",
      "composite_score    0\n",
      "Length: 169, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((combined_data_cleaned.isnull().sum()).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_cleaned = combined_data_cleaned.drop(columns='uid',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_03', 'urban_03', 'married_03', 'n_mar_03', 'edu_gru_03', 'n_living_child_03', 'migration_03', 'glob_hlth_03', 'adl_dress_03', 'adl_walk_03', 'adl_bath_03', 'adl_eat_03', 'adl_bed_03', 'adl_toilet_03', 'n_adl_03', 'iadl_money_03', 'iadl_meds_03', 'iadl_shop_03', 'iadl_meals_03', 'n_iadl_03', 'depressed_03', 'hard_03', 'restless_03', 'happy_03', 'lonely_03', 'enjoy_03', 'sad_03', 'tired_03', 'energetic_03', 'n_depr_03', 'cesd_depressed_03', 'hypertension_03', 'diabetes_03', 'resp_ill_03', 'arthritis_03', 'hrt_attack_03', 'stroke_03', 'cancer_03', 'n_illnesses_03', 'exer_3xwk_03', 'alcohol_03', 'tobacco_03', 'test_chol_03', 'test_tuber_03', 'test_diab_03', 'test_pres_03', 'hosp_03', 'visit_med_03', 'out_proc_03', 'visit_dental_03', 'imss_03', 'issste_03', 'pem_def_mar_03', 'insur_private_03', 'insur_other_03', 'insured_03', 'decis_personal_03', 'employment_03', 'age_12', 'urban_12', 'married_12', 'n_mar_12', 'edu_gru_12', 'n_living_child_12', 'migration_12', 'glob_hlth_12', 'adl_dress_12', 'adl_walk_12', 'adl_bath_12', 'adl_eat_12', 'adl_bed_12', 'adl_toilet_12', 'n_adl_12', 'iadl_money_12', 'iadl_meds_12', 'iadl_shop_12', 'iadl_meals_12', 'n_iadl_12', 'depressed_12', 'hard_12', 'restless_12', 'happy_12', 'lonely_12', 'enjoy_12', 'sad_12', 'tired_12', 'energetic_12', 'n_depr_12', 'cesd_depressed_12', 'hypertension_12', 'diabetes_12', 'resp_ill_12', 'arthritis_12', 'hrt_attack_12', 'stroke_12', 'cancer_12', 'n_illnesses_12', 'bmi_12', 'exer_3xwk_12', 'alcohol_12', 'tobacco_12', 'test_chol_12', 'test_tuber_12', 'test_diab_12', 'test_pres_12', 'hosp_12', 'visit_med_12', 'out_proc_12', 'visit_dental_12', 'imss_12', 'issste_12', 'pem_def_mar_12', 'insur_private_12', 'insur_other_12', 'insured_12', 'decis_famil_12', 'decis_personal_12', 'employment_12', 'vax_flu_12', 'vax_pneu_12', 'seg_pop_12', 'care_adult_12', 'care_child_12', 'volunteer_12', 'attends_class_12', 'attends_club_12', 'reads_12', 'games_12', 'table_games_12', 'comms_tel_comp_12', 'act_mant_12', 'tv_12', 'sewing_12', 'satis_ideal_12', 'satis_excel_12', 'satis_fine_12', 'cosas_imp_12', 'wouldnt_change_12', 'memory_12', 'ragender', 'rameduc_m', 'rafeduc_m', 'rearnings_03', 'hincome_03', 'hinc_business_03', 'hinc_rent_03', 'hinc_assets_03', 'hinc_cap_03', 'rinc_pension_03', 'rrelgimp_03', 'sgender_12', 'rearnings_12', 'searnings_12', 'hincome_12', 'hinc_business_12', 'hinc_rent_12', 'hinc_assets_12', 'hinc_cap_12', 'rinc_pension_12', 'sinc_pension_12', 'rrelgimp_12', 'rrfcntx_m_12', 'rsocact_m_12', 'rrelgwk_12', 'a34_12', 'j11_12', 'year', 'composite_score']\n"
     ]
    }
   ],
   "source": [
    "print((combined_data_cleaned.columns).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correlations greater than 0.6 or less than -0.6: 276\n",
      "Filtered Correlation Matrix (values > 0.6 or < -0.6):\n",
      "                 age_03  urban_03  married_03  n_mar_03  edu_gru_03  \\\n",
      "age_03              1.0       NaN         NaN       NaN         NaN   \n",
      "urban_03            NaN       1.0         NaN       NaN         NaN   \n",
      "married_03          NaN       NaN         1.0       NaN         NaN   \n",
      "n_mar_03            NaN       NaN         NaN       1.0         NaN   \n",
      "edu_gru_03          NaN       NaN         NaN       NaN         1.0   \n",
      "...                 ...       ...         ...       ...         ...   \n",
      "rrelgwk_12          NaN       NaN         NaN       NaN         NaN   \n",
      "a34_12              NaN       NaN         NaN       NaN         NaN   \n",
      "j11_12              NaN       NaN         NaN       NaN         NaN   \n",
      "year                NaN       NaN         NaN       NaN         NaN   \n",
      "composite_score     NaN       NaN         NaN       NaN         NaN   \n",
      "\n",
      "                 n_living_child_03  migration_03  glob_hlth_03  adl_dress_03  \\\n",
      "age_03                         NaN           NaN           NaN           NaN   \n",
      "urban_03                       NaN           NaN           NaN           NaN   \n",
      "married_03                     NaN           NaN           NaN           NaN   \n",
      "n_mar_03                       NaN           NaN           NaN           NaN   \n",
      "edu_gru_03                     NaN           NaN           NaN           NaN   \n",
      "...                            ...           ...           ...           ...   \n",
      "rrelgwk_12                     NaN           NaN           NaN           NaN   \n",
      "a34_12                         NaN           NaN           NaN           NaN   \n",
      "j11_12                         NaN           NaN           NaN           NaN   \n",
      "year                           NaN           NaN           NaN           NaN   \n",
      "composite_score                NaN           NaN           NaN           NaN   \n",
      "\n",
      "                 adl_walk_03  ...  rinc_pension_12  sinc_pension_12  \\\n",
      "age_03                   NaN  ...              NaN              NaN   \n",
      "urban_03                 NaN  ...              NaN              NaN   \n",
      "married_03               NaN  ...              NaN              NaN   \n",
      "n_mar_03                 NaN  ...              NaN              NaN   \n",
      "edu_gru_03               NaN  ...              NaN              NaN   \n",
      "...                      ...  ...              ...              ...   \n",
      "rrelgwk_12               NaN  ...              NaN              NaN   \n",
      "a34_12                   NaN  ...              NaN              NaN   \n",
      "j11_12                   NaN  ...              NaN              NaN   \n",
      "year                     NaN  ...              NaN              NaN   \n",
      "composite_score          NaN  ...              NaN              NaN   \n",
      "\n",
      "                 rrelgimp_12  rrfcntx_m_12  rsocact_m_12  rrelgwk_12  a34_12  \\\n",
      "age_03                   NaN           NaN           NaN         NaN     NaN   \n",
      "urban_03                 NaN           NaN           NaN         NaN     NaN   \n",
      "married_03               NaN           NaN           NaN         NaN     NaN   \n",
      "n_mar_03                 NaN           NaN           NaN         NaN     NaN   \n",
      "edu_gru_03               NaN           NaN           NaN         NaN     NaN   \n",
      "...                      ...           ...           ...         ...     ...   \n",
      "rrelgwk_12               NaN           NaN           NaN         1.0     NaN   \n",
      "a34_12                   NaN           NaN           NaN         NaN     1.0   \n",
      "j11_12                   NaN           NaN           NaN         NaN     NaN   \n",
      "year                     NaN           NaN           NaN         NaN     NaN   \n",
      "composite_score          NaN           NaN           NaN         NaN     NaN   \n",
      "\n",
      "                 j11_12  year  composite_score  \n",
      "age_03              NaN   NaN              NaN  \n",
      "urban_03            NaN   NaN              NaN  \n",
      "married_03          NaN   NaN              NaN  \n",
      "n_mar_03            NaN   NaN              NaN  \n",
      "edu_gru_03          NaN   NaN              NaN  \n",
      "...                 ...   ...              ...  \n",
      "rrelgwk_12          NaN   NaN              NaN  \n",
      "a34_12              NaN   NaN              NaN  \n",
      "j11_12              1.0   NaN              NaN  \n",
      "year                NaN   1.0              NaN  \n",
      "composite_score     NaN   NaN              1.0  \n",
      "\n",
      "[168 rows x 168 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = combined_data_cleaned.corr()\n",
    "\n",
    "# Count correlations greater than 0.6 or less than -0.6\n",
    "high_correlations_count = ((correlation_matrix > 0.6) | (correlation_matrix < -0.6)).sum().sum()\n",
    "\n",
    "print(f\"Total correlations greater than 0.6 or less than -0.6: {high_correlations_count}\")\n",
    "\n",
    "# Filter the correlation matrix\n",
    "filtered_corr = correlation_matrix[(correlation_matrix > 0.6) | (correlation_matrix < -0.6)]\n",
    "\n",
    "# Drop rows and columns that are entirely NaN\n",
    "filtered_corr_cleaned = filtered_corr.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "# Display the cleaned filtered correlation matrix\n",
    "print(\"Filtered Correlation Matrix (values > 0.6 or < -0.6):\")\n",
    "print(filtered_corr_cleaned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Health and Functionality Features\n",
    "\n",
    "- Overall Health Score: Combine self-reported global health and the number of ADL/IADL limitations to create a composite health score.\n",
    "\n",
    "- Formula: overall_health_score = (self_reported_health) - (n_adl + n_iadl)\n",
    "- Physical Limitations: Create a binary feature indicating any physical limitations.\n",
    "\n",
    "- Formula: physical_limitations = max(adl_dress, adl_walk, adl_bath, adl_eat, adl_bed, adl_toilet)\n",
    "- Depression Symptoms Score: Combine multiple depression-related features to create a composite depression score.\n",
    "\n",
    "- Formula: depression_score = n_depr + (depressed + sad + lonely + tired + restless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Health and Functionality Features\n",
    "# Overall Health Score: Composite health score\n",
    "combined_data_cleaned['overall_health_score'] = (\n",
    "    combined_data_cleaned['glob_hlth_03'] - \n",
    "    combined_data_cleaned['n_adl_03'] - \n",
    "    combined_data_cleaned['n_iadl_03']\n",
    ")\n",
    "\n",
    "# Physical Limitations: Binary feature indicating any physical limitations\n",
    "combined_data_cleaned['physical_limitations'] = (\n",
    "    (combined_data_cleaned[['adl_dress_03', 'adl_walk_03', 'adl_bath_03', \n",
    "                            'adl_eat_03', 'adl_bed_03', 'adl_toilet_03']] > 0).any(axis=1).astype(int)\n",
    ")\n",
    "\n",
    "# Depression Symptoms Score: Composite score based on depression-related features\n",
    "combined_data_cleaned['depression_score'] = (\n",
    "    combined_data_cleaned['n_depr_03'] + \n",
    "    combined_data_cleaned[['depressed_03', 'sad_03', 'lonely_03', 'tired_03', 'restless_03']].sum(axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Social Determinants of Health\n",
    "\n",
    "- Social Isolation Score: Create a score based on social activities, frequency of seeing friends and relatives, and participation in religious services.\n",
    "\n",
    "- Formula: social_isolation_score = (frequency_of_social_activities + rrelgwk) / 2\n",
    "- Economic Strain Index: Create an index that reflects financial stability based on income and health coverage.\n",
    "\n",
    "- ormula: economic_strain_index = (1 - insured) + (1 - (insur_private + insur_other)) + (hincome < threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Social Determinants of Health\n",
    "# Social Isolation Score: Score based on social activities and social contact\n",
    "combined_data_cleaned['social_isolation_score'] = (\n",
    "    (combined_data_cleaned['rrelgwk_12'] + combined_data_cleaned['seg_pop_12']) / 2\n",
    ")\n",
    "\n",
    "# Economic Strain Index: Index reflecting financial stability based on income and health coverage\n",
    "combined_data_cleaned['economic_strain_index'] = (\n",
    "    (1 - combined_data_cleaned['insured_12']) + \n",
    "    (1 - (combined_data_cleaned['insur_private_12'] + combined_data_cleaned['insur_other_12'])) + \n",
    "    (combined_data_cleaned['hincome_12'] < 20000).astype(int)  # Example threshold\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Lifestyle Features\n",
    "\n",
    "-Healthy Lifestyle Score: Create a score based on exercise, diet (considering alcohol and tobacco use), and health check-ups.\n",
    "\n",
    "- Formula: healthy_lifestyle_score = (exer_3xwk + (1 - alcohol) + (1 - tobacco) + test_chol + test_diab + test_pres)\n",
    "- Mental Engagement Score: Measure engagement in activities that can help maintain cognitive function (e.g., reading, games).\n",
    "\n",
    "Formula: mental_engagement_score = (reads + games + sewing + tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Lifestyle Features\n",
    "# Healthy Lifestyle Score: Score based on lifestyle factors\n",
    "combined_data_cleaned['healthy_lifestyle_score'] = (\n",
    "    combined_data_cleaned['exer_3xwk_12'] + \n",
    "    (1 - combined_data_cleaned['alcohol_12']) + \n",
    "    (1 - combined_data_cleaned['tobacco_12']) + \n",
    "    combined_data_cleaned[['test_chol_12', 'test_diab_12', 'test_pres_12']].sum(axis=1)\n",
    ")\n",
    "\n",
    "# Mental Engagement Score: Engagement in activities\n",
    "combined_data_cleaned['mental_engagement_score'] = (\n",
    "    combined_data_cleaned[['reads_12', 'games_12', 'sewing_12', 'tv_12']].sum(axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Interaction Features\n",
    "\n",
    "- Interaction of Age and Health: Capture the interaction between age group and self-reported health.\n",
    "\n",
    "- Formula: age_health_interaction = age * glob_hlth (where age is converted into a numeric value)\n",
    "- Education and Health: Create an interaction feature between education level and overall health score.\n",
    "\n",
    "- Formula: education_health_interaction = edu_gru * overall_health_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Interaction Features\n",
    "# Interaction of Age and Health: Interaction between age and self-reported health\n",
    "combined_data_cleaned['age_health_interaction'] = (\n",
    "    combined_data_cleaned['age_12'] * combined_data_cleaned['glob_hlth_12']\n",
    ")\n",
    "\n",
    "# Education and Health: Interaction feature between education level and overall health score\n",
    "combined_data_cleaned['education_health_interaction'] = (\n",
    "    combined_data_cleaned['edu_gru_12'] * combined_data_cleaned['overall_health_score']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Temporal Features\n",
    "\n",
    "- Change in Health Over Time: Calculate the change in the number of ADL and IADL limitations from 2003 to 2012.\n",
    "\n",
    "- Formula: change_in_adl = n_adl_12 - n_adl_03\n",
    "- Formula: change_in_iadl = n_iadl_12 - n_iadl_03\n",
    "- Longitudinal Change in Depression: Measure the change in depression score over the years.\n",
    "\n",
    "- Formula: change_in_depression = depression_score_12 - depression_score_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Temporal Features\n",
    "# Change in Health Over Time: Changes in ADL and IADL limitations from 2003 to 2012\n",
    "combined_data_cleaned['change_in_adl'] = (\n",
    "    combined_data_cleaned['n_adl_12'] - combined_data_cleaned['n_adl_03']\n",
    ")\n",
    "combined_data_cleaned['change_in_iadl'] = (\n",
    "    combined_data_cleaned['n_iadl_12'] - combined_data_cleaned['n_iadl_03']\n",
    ")\n",
    "\n",
    "# Longitudinal Change in Depression: Change in depression score over the years\n",
    "combined_data_cleaned['change_in_depression'] = (\n",
    "    combined_data_cleaned['n_depr_12'] - combined_data_cleaned['n_depr_03']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Aggregate Features\n",
    "\n",
    "- Aggregate Illness Count: Create a new feature that counts the number of chronic illnesses reported (hypertension, diabetes, etc.).\n",
    "\n",
    "- Formula: chronic_illness_count = (hypertension + diabetes + resp_ill + arthritis + hrt_attack + stroke + cancer)\n",
    "- Total Caregiving Index: A combined measure reflecting the amount of time spent caregiving, considering both adult and child care.\n",
    "\n",
    "- Formula: total_caregiving_index = care_adult + care_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Aggregate Features\n",
    "# Aggregate Illness Count: Counting chronic illnesses\n",
    "combined_data_cleaned['chronic_illness_count'] = (\n",
    "    combined_data_cleaned[['hypertension_03', 'diabetes_03', 'resp_ill_03', \n",
    "                           'arthritis_03', 'hrt_attack_03', 'stroke_03', \n",
    "                           'cancer_03']].sum(axis=1)\n",
    ")\n",
    "\n",
    "# Total Caregiving Index: Time spent caregiving for adults and children\n",
    "combined_data_cleaned['total_caregiving_index'] = (\n",
    "    combined_data_cleaned['care_adult_12'] + \n",
    "    combined_data_cleaned['care_child_12']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>adl_walk_03</th>\n",
       "      <th>...</th>\n",
       "      <th>economic_strain_index</th>\n",
       "      <th>healthy_lifestyle_score</th>\n",
       "      <th>mental_engagement_score</th>\n",
       "      <th>age_health_interaction</th>\n",
       "      <th>education_health_interaction</th>\n",
       "      <th>change_in_adl</th>\n",
       "      <th>change_in_iadl</th>\n",
       "      <th>change_in_depression</th>\n",
       "      <th>chronic_illness_count</th>\n",
       "      <th>total_caregiving_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>-3.485267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.637394</td>\n",
       "      <td>-0.073687</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.879131</td>\n",
       "      <td>0.926313</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.879131</td>\n",
       "      <td>0.926313</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_03  urban_03  married_03  n_mar_03  edu_gru_03  n_living_child_03  \\\n",
       "0     1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "1     1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "2     1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "3     1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "4     1.0       1.0         3.0  1.000000         3.0                1.0   \n",
       "\n",
       "   migration_03  glob_hlth_03  adl_dress_03  adl_walk_03  ...  \\\n",
       "0           0.0           4.0           0.0          0.0  ...   \n",
       "1           0.0           4.0           0.0          0.0  ...   \n",
       "2           0.0           4.0           0.0          0.0  ...   \n",
       "3           0.0           4.0           0.0          0.0  ...   \n",
       "4           0.0           4.0           0.0          0.0  ...   \n",
       "\n",
       "   economic_strain_index  healthy_lifestyle_score  mental_engagement_score  \\\n",
       "0                    0.0                      5.0                      2.0   \n",
       "1                    1.0                      6.0                      3.0   \n",
       "2                    2.0                      5.0                      3.0   \n",
       "3                    2.0                      5.0                      3.0   \n",
       "4                    2.0                      4.0                      3.0   \n",
       "\n",
       "   age_health_interaction  education_health_interaction  change_in_adl  \\\n",
       "0                     8.0                      0.000000       0.115188   \n",
       "1                     4.0                     11.637394      -0.073687   \n",
       "2                     4.0                      3.879131       0.926313   \n",
       "3                     4.0                      3.879131       0.926313   \n",
       "4                     8.0                     12.000000       0.000000   \n",
       "\n",
       "   change_in_iadl  change_in_depression  chronic_illness_count  \\\n",
       "0       -0.047181             -3.485267                    0.0   \n",
       "1       -0.047181              0.514733                    0.0   \n",
       "2       -0.047181              0.514733                    0.0   \n",
       "3       -0.047181              0.514733                    0.0   \n",
       "4        0.000000              2.000000                    1.0   \n",
       "\n",
       "   total_caregiving_index  \n",
       "0                     0.0  \n",
       "1                     1.0  \n",
       "2                     1.0  \n",
       "3                     1.0  \n",
       "4                     0.0  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assuming `combined_data_cleaned` is already loaded\n",
    "X = combined_data_cleaned.drop(columns=['composite_score'])\n",
    "y = combined_data_cleaned['composite_score']\n",
    "\n",
    "# Preprocessing: Scaling and Handling Outliers\n",
    "# Pipeline for continuous features\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handling NaNs\n",
    "    ('scaler', StandardScaler())  # Scaling the data\n",
    "])\n",
    "\n",
    "# Applying the transformation\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, numerical_features)\n",
    "])\n",
    "\n",
    "# Preprocessing the data\n",
    "X = preprocessor.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SelectKBest with Different Scoring Functions\n",
    "\n",
    "We’ll use SelectKBest with chi2 (requires non-negative data) and mutual_info_regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, mutual_info_regression, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensuring non-negative data for chi2\n",
    "X_non_neg = np.where(X < 0, X - X.min(axis=0), X)\n",
    "\n",
    "# SelectKBest with chi2\n",
    "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi2_selector.fit(X_non_neg, y)\n",
    "chi2_scores = chi2_selector.scores_\n",
    "\n",
    "# SelectKBest with mutual information\n",
    "mutual_info_selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "mutual_info_selector.fit(X, y)\n",
    "mutual_info_scores = mutual_info_selector.scores_\n",
    "\n",
    "# SelectKBest with f_regression (ANOVA F-value)\n",
    "f_reg_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "f_reg_selector.fit(X, y)\n",
    "f_reg_scores = f_reg_selector.scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    feature  average_rank\n",
      "0                edu_gru_12     15.000000\n",
      "1                  games_12     23.000000\n",
      "2   mental_engagement_score     27.333333\n",
      "3                 rameduc_m     28.333333\n",
      "4              rearnings_12     28.666667\n",
      "5                edu_gru_03     31.333333\n",
      "6              rearnings_03     31.333333\n",
      "7            table_games_12     34.000000\n",
      "8                    j11_12     34.000000\n",
      "9                  reads_12     35.000000\n",
      "10          rinc_pension_12     38.333333\n",
      "11  healthy_lifestyle_score     39.666667\n",
      "12                  hard_03     42.333333\n",
      "13                rafeduc_m     43.000000\n",
      "14    economic_strain_index     43.333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_regression, f_regression\n",
    "import pandas as pd\n",
    "\n",
    "# Adjust actual_feature_names to match the number of features in X\n",
    "if not isinstance(X, pd.DataFrame):\n",
    "    # Match feature names to the shape of X if they're mismatched\n",
    "    actual_feature_names = combined_data_cleaned.columns[:X.shape[1]].tolist()\n",
    "    X_df = pd.DataFrame(X, columns=actual_feature_names)\n",
    "else:\n",
    "    X_df = X\n",
    "\n",
    "# Ensure non-negative data for chi2 by adjusting any negative values\n",
    "X_non_neg = X_df.apply(lambda x: x - x.min() if x.min() < 0 else x)\n",
    "\n",
    "# SelectKBest with chi2\n",
    "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "chi2_selector.fit(X_non_neg, y)\n",
    "chi2_scores = chi2_selector.scores_\n",
    "\n",
    "# SelectKBest with mutual information\n",
    "mutual_info_selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
    "mutual_info_selector.fit(X_df, y)\n",
    "mutual_info_scores = mutual_info_selector.scores_\n",
    "\n",
    "# SelectKBest with f_regression (ANOVA F-value)\n",
    "f_reg_selector = SelectKBest(score_func=f_regression, k='all')\n",
    "f_reg_selector.fit(X_df, y)\n",
    "f_reg_scores = f_reg_selector.scores_\n",
    "\n",
    "# Combining scores into a DataFrame for ranking\n",
    "feature_scores = pd.DataFrame({\n",
    "    'feature': X_df.columns,\n",
    "    'chi2': chi2_scores,\n",
    "    'mutual_info': mutual_info_scores,\n",
    "    'f_regression': f_reg_scores\n",
    "})\n",
    "\n",
    "# Ranking features in descending order for each score type\n",
    "feature_scores['chi2_rank'] = feature_scores['chi2'].rank(ascending=False)\n",
    "feature_scores['mutual_info_rank'] = feature_scores['mutual_info'].rank(ascending=False)\n",
    "feature_scores['f_regression_rank'] = feature_scores['f_regression'].rank(ascending=False)\n",
    "\n",
    "# Calculating the average rank across methods\n",
    "feature_scores['average_rank'] = feature_scores[['chi2_rank', 'mutual_info_rank', 'f_regression_rank']].mean(axis=1)\n",
    "\n",
    "# Sorting features by their average rank (lower rank means higher importance)\n",
    "most_important_features = feature_scores.sort_values('average_rank').reset_index(drop=True)\n",
    "\n",
    "# Displaying the top features based on their average rank\n",
    "print(most_important_features[['feature', 'average_rank']].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>adl_walk_03</th>\n",
       "      <th>...</th>\n",
       "      <th>economic_strain_index</th>\n",
       "      <th>healthy_lifestyle_score</th>\n",
       "      <th>mental_engagement_score</th>\n",
       "      <th>age_health_interaction</th>\n",
       "      <th>education_health_interaction</th>\n",
       "      <th>change_in_adl</th>\n",
       "      <th>change_in_iadl</th>\n",
       "      <th>change_in_depression</th>\n",
       "      <th>chronic_illness_count</th>\n",
       "      <th>total_caregiving_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>-3.485267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.637394</td>\n",
       "      <td>-0.073687</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.879131</td>\n",
       "      <td>0.926313</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.133275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.879131</td>\n",
       "      <td>0.926313</td>\n",
       "      <td>-0.047181</td>\n",
       "      <td>0.514733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4339</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3984 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age_03  urban_03  married_03  n_mar_03  edu_gru_03  n_living_child_03  \\\n",
       "0        1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "1        1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "2        1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "3        1.0       1.0         3.0  1.133275         3.0                1.0   \n",
       "4        1.0       1.0         3.0  1.000000         3.0                1.0   \n",
       "...      ...       ...         ...       ...         ...                ...   \n",
       "4337     1.0       0.0         1.0  1.000000         1.0                4.0   \n",
       "4338     1.0       0.0         1.0  1.000000         1.0                4.0   \n",
       "4339     1.0       0.0         3.0  1.000000         1.0                1.0   \n",
       "4340     1.0       0.0         3.0  1.000000         1.0                1.0   \n",
       "4342     1.0       1.0         1.0  3.000000         0.0                4.0   \n",
       "\n",
       "      migration_03  glob_hlth_03  adl_dress_03  adl_walk_03  ...  \\\n",
       "0              0.0           4.0           0.0          0.0  ...   \n",
       "1              0.0           4.0           0.0          0.0  ...   \n",
       "2              0.0           4.0           0.0          0.0  ...   \n",
       "3              0.0           4.0           0.0          0.0  ...   \n",
       "4              0.0           4.0           0.0          0.0  ...   \n",
       "...            ...           ...           ...          ...  ...   \n",
       "4337           0.0           5.0           0.0          0.0  ...   \n",
       "4338           0.0           5.0           0.0          0.0  ...   \n",
       "4339           0.0           4.0           0.0          0.0  ...   \n",
       "4340           0.0           4.0           0.0          0.0  ...   \n",
       "4342           0.0           4.0           0.0          0.0  ...   \n",
       "\n",
       "      economic_strain_index  healthy_lifestyle_score  mental_engagement_score  \\\n",
       "0                       0.0                      5.0                      2.0   \n",
       "1                       1.0                      6.0                      3.0   \n",
       "2                       2.0                      5.0                      3.0   \n",
       "3                       2.0                      5.0                      3.0   \n",
       "4                       2.0                      4.0                      3.0   \n",
       "...                     ...                      ...                      ...   \n",
       "4337                    1.0                      4.0                      3.0   \n",
       "4338                    1.0                      4.0                      3.0   \n",
       "4339                    2.0                      3.0                      0.0   \n",
       "4340                    2.0                      3.0                      0.0   \n",
       "4342                    1.0                      6.0                      1.0   \n",
       "\n",
       "      age_health_interaction  education_health_interaction  change_in_adl  \\\n",
       "0                        8.0                      0.000000       0.115188   \n",
       "1                        4.0                     11.637394      -0.073687   \n",
       "2                        4.0                      3.879131       0.926313   \n",
       "3                        4.0                      3.879131       0.926313   \n",
       "4                        8.0                     12.000000       0.000000   \n",
       "...                      ...                           ...            ...   \n",
       "4337                     4.0                      5.000000       0.000000   \n",
       "4338                     4.0                      5.000000       0.000000   \n",
       "4339                     6.0                      4.000000       0.000000   \n",
       "4340                     6.0                      4.000000       0.000000   \n",
       "4342                     8.0                      0.000000       0.000000   \n",
       "\n",
       "      change_in_iadl  change_in_depression  chronic_illness_count  \\\n",
       "0          -0.047181             -3.485267                    0.0   \n",
       "1          -0.047181              0.514733                    0.0   \n",
       "2          -0.047181              0.514733                    0.0   \n",
       "3          -0.047181              0.514733                    0.0   \n",
       "4           0.000000              2.000000                    1.0   \n",
       "...              ...                   ...                    ...   \n",
       "4337        0.000000              1.000000                    2.0   \n",
       "4338        0.000000              1.000000                    2.0   \n",
       "4339        0.000000              1.000000                    2.0   \n",
       "4340        0.000000              1.000000                    2.0   \n",
       "4342        0.000000             -1.000000                    1.0   \n",
       "\n",
       "      total_caregiving_index  \n",
       "0                        0.0  \n",
       "1                        1.0  \n",
       "2                        1.0  \n",
       "3                        1.0  \n",
       "4                        0.0  \n",
       "...                      ...  \n",
       "4337                     0.0  \n",
       "4338                     0.0  \n",
       "4339                     0.0  \n",
       "4340                     0.0  \n",
       "4342                     1.0  \n",
       "\n",
       "[3984 rows x 182 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances from Tree-Based Models\n",
    "\n",
    "We’ll use RandomForestRegressor and DecisionTreeRegressor to calculate importance scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances from Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X, y)\n",
    "rf_importances = rf.feature_importances_\n",
    "\n",
    "# Feature importances from Decision Tree\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X, y)\n",
    "dt_importances = dt.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances from Lasso Regression\n",
    "\n",
    "Lasso regression performs feature selection by applying L1 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Lasso Regression\n",
    "lasso = LassoCV(cv=5, random_state=42)\n",
    "lasso.fit(X, y)\n",
    "lasso_importances = np.abs(lasso.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing Feature Importance Scores \n",
    "\n",
    "Combine all feature importance scores into a DataFrame for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  average_rank\n",
      "0                edu_gru_12           9.4\n",
      "1                    j11_12          25.0\n",
      "2                 rameduc_m          26.2\n",
      "3                    age_12          27.6\n",
      "4     economic_strain_index          27.6\n",
      "5            table_games_12          32.4\n",
      "6                  reads_12          32.4\n",
      "7              rrfcntx_m_12          32.4\n",
      "8   healthy_lifestyle_score          36.2\n",
      "9         n_living_child_12          36.2\n",
      "10             rearnings_12          40.2\n",
      "11               hincome_03          40.8\n",
      "12             rsocact_m_12          41.4\n",
      "13            care_child_12          41.8\n",
      "14                   age_03          41.8\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already run your feature selection code and have your scores calculated\n",
    "\n",
    "# Combining scores into a DataFrame for ranking\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_df.columns,  # Use X_df to access the column names\n",
    "    'Chi2': chi2_scores,\n",
    "    'Mutual_Info': mutual_info_scores,\n",
    "    'F_Regression': f_reg_scores,\n",
    "    'DT_Importances': dt_importances,\n",
    "    'Lasso_Importances': lasso_importances\n",
    "})\n",
    "\n",
    "# Ranking features in descending order for each score type\n",
    "feature_importances_df['chi2_rank'] = feature_importances_df['Chi2'].rank(ascending=False)\n",
    "feature_importances_df['mutual_info_rank'] = feature_importances_df['Mutual_Info'].rank(ascending=False)\n",
    "feature_importances_df['f_regression_rank'] = feature_importances_df['F_Regression'].rank(ascending=False)\n",
    "feature_importances_df['dt_rank'] = feature_importances_df['DT_Importances'].rank(ascending=False)\n",
    "feature_importances_df['lasso_rank'] = feature_importances_df['Lasso_Importances'].rank(ascending=False)\n",
    "\n",
    "# Calculating the average rank across methods\n",
    "feature_importances_df['average_rank'] = feature_importances_df[['chi2_rank', 'mutual_info_rank', 'f_regression_rank', 'dt_rank', 'lasso_rank']].mean(axis=1)\n",
    "\n",
    "# Sorting features by their average rank (lower rank means higher importance)\n",
    "most_important_features = feature_importances_df.sort_values('average_rank').reset_index(drop=True)\n",
    "\n",
    "# Displaying the top features based on their average rank\n",
    "print(most_important_features[['Feature', 'average_rank']].head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the Most Frequently Ranked Features\n",
    "\n",
    "Now, we will find the top features that consistently rank highly across different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features across all methods: ['edu_gru_12', 'j11_12', 'rameduc_m', 'age_12', 'economic_strain_index', 'table_games_12', 'reads_12', 'rrfcntx_m_12', 'healthy_lifestyle_score', 'n_living_child_12', 'rearnings_12', 'hincome_03', 'rsocact_m_12', 'care_child_12', 'age_03']\n"
     ]
    }
   ],
   "source": [
    "# Sorting features by average rank\n",
    "top_features = feature_importances_df.sort_values(by='average_rank').head(15)\n",
    "top_features_list = top_features['Feature'].tolist()\n",
    "print(\"Top features across all methods:\", top_features_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the Number of Top Features: Decide on the number of top features to keep. For example, let’s say we want the top 15 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Feature', 'Chi2', 'Mutual_Info', 'F_Regression', 'DT_Importances',\n",
      "       'Lasso_Importances', 'chi2_rank', 'mutual_info_rank',\n",
      "       'f_regression_rank', 'dt_rank', 'lasso_rank', 'average_rank'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(most_important_features.columns)\n",
    "top_features = most_important_features['Feature'].head(15).tolist()\n",
    "\n",
    "# Extract the top features from X_df based on the identified top features\n",
    "X_top = X_df[top_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_top_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-f96bb4de3478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_top_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_top_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_top_scaled = scaler.fit_transform(X_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended Metrics for Different Scenarios\n",
    "\n",
    "High Focus on Identifying All Sick Individuals:\n",
    "\n",
    "Recall: This should be your primary metric if maximizing the count of correctly identified sick individuals is most important.\n",
    "Balance Between Identifying Sick Individuals and Avoiding False Alarms:\n",
    "\n",
    "F1-score: This is helpful if you want a balance between high recall (catching sick individuals) and high precision (avoiding false positives).\n",
    "Secondary Metrics for Insight:\n",
    "\n",
    "Confusion Matrix: To visually check true positives, false positives, and false negatives.\n",
    "ROC-AUC: To check the model’s overall ability to distinguish sick versus healthy individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Custom Metrics for Evaluation\n",
    "# ==========================\n",
    "def recall_scorer(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "def f1_scorer(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Define the evaluation metrics\n",
    "scoring = {\n",
    "    'Recall': make_scorer(recall_scorer),\n",
    "    'F1-Score': make_scorer(f1_scorer),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Results Storage\n",
    "# ==========================\n",
    "results = []\n",
    "\n",
    "# ==========================\n",
    "# Cross-Validation Setup\n",
    "# ==========================\n",
    "cv = TimeSeriesSplit(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge_model = Ridge()\n",
    "ridge_param_grid = {'alpha': [0.1, 1.0, 10]}\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "ridge_grid_search = GridSearchCV(ridge_model, ridge_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "ridge_best_model = ridge_grid_search.best_estimator_\n",
    "ridge_y_pred = ridge_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for Ridge Regression\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_y_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_y_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "ridge_r2 = r2_score(y_test, ridge_y_pred)\n",
    "\n",
    "# Store results for Ridge Regression\n",
    "ridge_results = {\n",
    "    'Model': 'Ridge',\n",
    "    'Best Parameters': ridge_grid_search.best_params_,\n",
    "    'MAE': ridge_mae,\n",
    "    'MSE': ridge_mse,\n",
    "    'RMSE': ridge_rmse,\n",
    "    'R-squared': ridge_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso_model = Lasso()\n",
    "lasso_param_grid = {'alpha': [0.01, 0.1, 1.0]}\n",
    "\n",
    "lasso_grid_search = GridSearchCV(lasso_model, lasso_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "lasso_best_model = lasso_grid_search.best_estimator_\n",
    "lasso_y_pred = lasso_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for Lasso Regression\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_y_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_y_pred)\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "lasso_r2 = r2_score(y_test, lasso_y_pred)\n",
    "\n",
    "# Store results for Lasso Regression\n",
    "lasso_results = {\n",
    "    'Model': 'Lasso',\n",
    "    'Best Parameters': lasso_grid_search.best_params_,\n",
    "    'MAE': lasso_mae,\n",
    "    'MSE': lasso_mse,\n",
    "    'RMSE': lasso_rmse,\n",
    "    'R-squared': lasso_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Neighbors Regression\n",
    "knn_model = KNeighborsRegressor()\n",
    "knn_param_grid = {'n_neighbors': [3, 5, 7]}\n",
    "\n",
    "knn_grid_search = GridSearchCV(knn_model, knn_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "knn_best_model = knn_grid_search.best_estimator_\n",
    "knn_y_pred = knn_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for K-Neighbors Regression\n",
    "knn_mae = mean_absolute_error(y_test, knn_y_pred)\n",
    "knn_mse = mean_squared_error(y_test, knn_y_pred)\n",
    "knn_rmse = np.sqrt(knn_mse)\n",
    "knn_r2 = r2_score(y_test, knn_y_pred)\n",
    "\n",
    "# Store results for K-Neighbors Regression\n",
    "knn_results = {\n",
    "    'Model': 'KNeighbors',\n",
    "    'Best Parameters': knn_grid_search.best_params_,\n",
    "    'MAE': knn_mae,\n",
    "    'MSE': knn_mse,\n",
    "    'RMSE': knn_rmse,\n",
    "    'R-squared': knn_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_param_grid = {'n_estimators': [50, 100, 200]}\n",
    "\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "rf_y_pred = rf_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for Random Forest Regression\n",
    "rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "\n",
    "# Store results for Random Forest Regression\n",
    "rf_results = {\n",
    "    'Model': 'Random Forest',\n",
    "    'Best Parameters': rf_grid_search.best_params_,\n",
    "    'MAE': rf_mae,\n",
    "    'MSE': rf_mse,\n",
    "    'RMSE': rf_rmse,\n",
    "    'R-squared': rf_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regression\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "\n",
    "gb_grid_search = GridSearchCV(gb_model, gb_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "gb_best_model = gb_grid_search.best_estimator_\n",
    "gb_y_pred = gb_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for Gradient Boosting Regression\n",
    "gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_rmse = np.sqrt(gb_mse)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "\n",
    "# Store results for Gradient Boosting Regression\n",
    "gb_results = {\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'Best Parameters': gb_grid_search.best_params_,\n",
    "    'MAE': gb_mae,\n",
    "    'MSE': gb_mse,\n",
    "    'RMSE': gb_rmse,\n",
    "    'R-squared': gb_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regression\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "\n",
    "xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "xgb_best_model = xgb_grid_search.best_estimator_\n",
    "xgb_y_pred = xgb_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for XGBoost Regression\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_y_pred)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_y_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_r2 = r2_score(y_test, xgb_y_pred)\n",
    "\n",
    "# Store results for XGBoost Regression\n",
    "xgb_results = {\n",
    "    'Model': 'XGBoost',\n",
    "    'Best Parameters': xgb_grid_search.best_params_,\n",
    "    'MAE': xgb_mae,\n",
    "    'MSE': xgb_mse,\n",
    "    'RMSE': xgb_rmse,\n",
    "    'R-squared': xgb_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 236\n",
      "[LightGBM] [Info] Number of data points in the train set: 3187, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 157.892375\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Regression\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "\n",
    "lgbm_grid_search = GridSearchCV(lgbm_model, lgbm_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "lgbm_grid_search.fit(X_train, y_train)\n",
    "lgbm_best_model = lgbm_grid_search.best_estimator_\n",
    "lgbm_y_pred = lgbm_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for LightGBM Regression\n",
    "lgbm_mae = mean_absolute_error(y_test, lgbm_y_pred)\n",
    "lgbm_mse = mean_squared_error(y_test, lgbm_y_pred)\n",
    "lgbm_rmse = np.sqrt(lgbm_mse)\n",
    "lgbm_r2 = r2_score(y_test, lgbm_y_pred)\n",
    "\n",
    "# Store results for LightGBM Regression\n",
    "lgbm_results = {\n",
    "    'Model': 'LightGBM',\n",
    "    'Best Parameters': lgbm_grid_search.best_params_,\n",
    "    'MAE': lgbm_mae,\n",
    "    'MSE': lgbm_mse,\n",
    "    'RMSE': lgbm_rmse,\n",
    "    'R-squared': lgbm_r2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Regression\n",
    "cat_model = CatBoostRegressor(verbose=0)\n",
    "cat_param_grid = {'iterations': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "\n",
    "cat_grid_search = GridSearchCV(cat_model, cat_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "cat_grid_search.fit(X_train, y_train)\n",
    "cat_best_model = cat_grid_search.best_estimator_\n",
    "cat_y_pred = cat_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for CatBoost Regression\n",
    "cat_mae = mean_absolute_error(y_test, cat_y_pred)\n",
    "cat_mse = mean_squared_error(y_test, cat_y_pred)\n",
    "cat_rmse = np.sqrt(cat_mse)\n",
    "cat_r2 = r2_score(y_test, cat_y_pred)\n",
    "\n",
    "# Store results for CatBoost Regression\n",
    "cat_results = {\n",
    "    'Model': 'CatBoost',\n",
    "    'Best Parameters': cat_grid_search.best_params_,\n",
    "    'MAE': cat_mae,\n",
    "    'MSE': cat_mse,\n",
    "    'RMSE': cat_rmse,\n",
    "    'R-squared': cat_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model                               Best Parameters        MAE  \\\n",
      "0              Ridge                                 {'alpha': 10}  32.194873   \n",
      "1              Lasso                                {'alpha': 0.1}  32.200801   \n",
      "2         KNeighbors                            {'n_neighbors': 7}  35.085141   \n",
      "3      Random Forest                         {'n_estimators': 200}  30.561123   \n",
      "4  Gradient Boosting    {'learning_rate': 0.1, 'n_estimators': 50}  32.091949   \n",
      "5            XGBoost  {'learning_rate': 0.05, 'n_estimators': 100}  31.751859   \n",
      "6           LightGBM  {'learning_rate': 0.05, 'n_estimators': 100}  31.853513   \n",
      "7           CatBoost     {'iterations': 100, 'learning_rate': 0.1}  31.753972   \n",
      "\n",
      "           MSE       RMSE  R-squared  \n",
      "0  1687.586761  41.080248   0.529308  \n",
      "1  1687.883441  41.083859   0.529225  \n",
      "2  1996.999155  44.687796   0.443008  \n",
      "3  1602.757876  40.034459   0.552968  \n",
      "4  1675.471961  40.932529   0.532687  \n",
      "5  1661.244342  40.758365   0.536655  \n",
      "6  1684.076611  41.037502   0.530287  \n",
      "7  1643.254107  40.537071   0.541673  \n"
     ]
    }
   ],
   "source": [
    "# Combine all results into a DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    ridge_results,\n",
    "    lasso_results,\n",
    "    knn_results,\n",
    "    rf_results,\n",
    "    gb_results,\n",
    "    xgb_results,\n",
    "    lgbm_results,\n",
    "    cat_results\n",
    "])\n",
    "\n",
    "# Print the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>year</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>time</th>\n",
       "      <th>seg_pop_12</th>\n",
       "      <th>comms_tel_comp_12</th>\n",
       "      <th>tv_12</th>\n",
       "      <th>vax_flu_12</th>\n",
       "      <th>table_games_12</th>\n",
       "      <th>satis_excel_12</th>\n",
       "      <th>...</th>\n",
       "      <th>hinc_assets</th>\n",
       "      <th>hinc_cap</th>\n",
       "      <th>rinc_pension</th>\n",
       "      <th>sinc_pension</th>\n",
       "      <th>rrelgimp</th>\n",
       "      <th>rrfcntx_m</th>\n",
       "      <th>rsocact_m</th>\n",
       "      <th>rrelgwk</th>\n",
       "      <th>a34</th>\n",
       "      <th>j11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aace</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aanz</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aanz</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aape</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid    year  composite_score  time  seg_pop_12  comms_tel_comp_12  tv_12  \\\n",
       "0  aace  2021.0            175.0     3         1.0                0.0    1.0   \n",
       "1  aace  2021.0            175.0    12         1.0                0.0    1.0   \n",
       "2  aanz  2021.0            206.0     3         0.0                0.0    1.0   \n",
       "3  aanz  2021.0            206.0    12         0.0                0.0    1.0   \n",
       "4  aape  2016.0            161.0     3         0.0                1.0    1.0   \n",
       "\n",
       "   vax_flu_12  table_games_12  satis_excel_12  ...  hinc_assets  hinc_cap  \\\n",
       "0         0.0             0.0             3.0  ...          NaN       NaN   \n",
       "1         0.0             0.0             3.0  ...          0.0   10000.0   \n",
       "2         1.0             0.0             2.0  ...          NaN       NaN   \n",
       "3         1.0             0.0             2.0  ...          0.0       0.0   \n",
       "4         0.0             0.0             1.0  ...          NaN       NaN   \n",
       "\n",
       "   rinc_pension  sinc_pension  rrelgimp  rrfcntx_m  rsocact_m  rrelgwk  a34  \\\n",
       "0           NaN           NaN       NaN        NaN        NaN      NaN  NaN   \n",
       "1           0.0           0.0       2.0        9.0        9.0      0.0  NaN   \n",
       "2           NaN           NaN       NaN        NaN        NaN      NaN  NaN   \n",
       "3           0.0           0.0       1.0        9.0        1.0      0.0  NaN   \n",
       "4           NaN           NaN       NaN        NaN        NaN      NaN  NaN   \n",
       "\n",
       "   j11  \n",
       "0  NaN  \n",
       "1  2.0  \n",
       "2  NaN  \n",
       "3  2.0  \n",
       "4  NaN  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert wide to long format\n",
    "data_long = pd.wide_to_long(\n",
    "    long_data ,\n",
    "    stubnames=[\n",
    "        'age', 'urban', 'married', 'n_mar', 'edu_gru', 'n_living_child', 'migration', \n",
    "        'glob_hlth', 'adl_dress', 'adl_walk', 'adl_bath', 'adl_eat', 'adl_bed', 'adl_toilet', \n",
    "        'n_adl', 'iadl_money', 'iadl_meds', 'iadl_shop', 'iadl_meals', 'n_iadl', 'depressed', \n",
    "        'hard', 'restless', 'happy', 'lonely', 'enjoy', 'sad', 'tired', 'energetic', 'n_depr', \n",
    "        'cesd_depressed', 'hypertension', 'diabetes', 'resp_ill', 'arthritis', 'hrt_attack', \n",
    "        'stroke', 'cancer', 'n_illnesses', 'bmi', 'exer_3xwk', 'alcohol', 'tobacco', \n",
    "        'test_chol', 'test_tuber', 'test_diab', 'test_pres', 'hosp', 'visit_med', \n",
    "        'out_proc', 'visit_dental', 'imss', 'issste', 'pem_def_mar', 'insur_private', \n",
    "        'insur_other', 'insured', 'decis_famil', 'decis_personal', 'employment', \n",
    "        'rjob_hrswk', 'rjlocc_m', 'rjob_end', 'rjobend_reason', 'rearnings', \n",
    "        'searnings', 'hincome', 'hinc_business', 'hinc_rent', 'hinc_assets', 'hinc_cap', \n",
    "        'rinc_pension', 'sinc_pension', 'rrelgimp', 'rrfcntx_m', 'rsocact_m', 'rrelgwk', \n",
    "        'a34', 'j11'\n",
    "    ],\n",
    "    i=['uid', 'year', 'composite_score'],  # Use 'uid', 'year', and 'composite_score' as identifiers\n",
    "    j='time',  # Variable to capture time (03 or 12)\n",
    "    sep='_',  # Separator used in wide-format column names\n",
    "    suffix='\\\\d+'  # Regular expression to capture suffixes (03 or 12)\n",
    ").reset_index()\n",
    "\n",
    "# Display the first few rows to verify\n",
    "data_long.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10324, 113)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10244, 10208, 10192, 10192, 9036, 8995, 7128, 7040, 6588, 5482, 5470, 5468, 5275, 4952, 4592, 4395, 4395, 3652, 3371, 2270, 2251, 2247, 2247, 2228, 2225, 2223, 2222, 2220, 2216, 2211, 2210, 2210, 2209, 2208, 2207, 2206, 2206, 2205, 2205, 2205, 2205, 2204, 2204, 2204, 1962, 1904, 1884, 1882, 1879, 1874, 1866, 1863, 1859, 1859, 1858, 1851, 1850, 1848, 1847, 1847, 1847, 1844, 1842, 1841, 1841, 1840, 1840, 1840, 1840, 1839, 1839, 1838, 1837, 1837, 1837, 1836, 1836, 1835, 1835, 1835, 1835, 1819, 1819, 1819, 1819, 1638, 1638, 1506, 1250, 840, 790, 722, 704, 692, 658, 642, 640, 640, 624, 622, 620, 618, 618, 616, 616, 616, 612, 612, 612, 266, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Printing the missing values sorted in descending order\n",
    "print(data_long.isna().sum().sort_values(ascending=False).to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a16a_12            10244\n",
      "a22_12             10208\n",
      "a33b_12            10192\n",
      "a21_12             10192\n",
      "rjob_end            9036\n",
      "                   ...  \n",
      "attends_club_12      612\n",
      "seg_pop_12           266\n",
      "time                   0\n",
      "ragender               0\n",
      "uid                    0\n",
      "Length: 113, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Printing the missing values with column names, sorted in descending order\n",
    "print(data_long.isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data_long.select_dtypes(include=['float64', 'int64'])\n",
    "categorical_data = data_long.select_dtypes(exclude=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns remaining after dropping those with more than 40% missing values:\n",
      "Index(['uid', 'year', 'composite_score', 'time', 'seg_pop_12',\n",
      "       'comms_tel_comp_12', 'tv_12', 'vax_flu_12', 'table_games_12',\n",
      "       'satis_excel_12', 'volunteer_12', 'wouldnt_change_12',\n",
      "       'attends_club_12', 'reads_12', 'ragender', 'care_child_12',\n",
      "       'satis_ideal_12', 'games_12', 'satis_fine_12', 'attends_class_12',\n",
      "       'act_mant_12', 'cosas_imp_12', 'vax_pneu_12', 'memory_12', 'sewing_12',\n",
      "       'sgender_12', 'care_adult_12', 'rameduc_m', 'rafeduc_m', 'age', 'urban',\n",
      "       'married', 'n_mar', 'edu_gru', 'n_living_child', 'migration',\n",
      "       'glob_hlth', 'adl_dress', 'adl_walk', 'adl_bath', 'adl_eat', 'adl_bed',\n",
      "       'adl_toilet', 'n_adl', 'iadl_money', 'iadl_meds', 'iadl_shop',\n",
      "       'iadl_meals', 'n_iadl', 'depressed', 'hard', 'restless', 'happy',\n",
      "       'lonely', 'enjoy', 'sad', 'tired', 'energetic', 'n_depr',\n",
      "       'cesd_depressed', 'hypertension', 'diabetes', 'resp_ill', 'arthritis',\n",
      "       'hrt_attack', 'stroke', 'cancer', 'n_illnesses', 'bmi', 'exer_3xwk',\n",
      "       'alcohol', 'tobacco', 'test_chol', 'test_tuber', 'test_diab',\n",
      "       'test_pres', 'hosp', 'visit_med', 'out_proc', 'visit_dental', 'imss',\n",
      "       'issste', 'pem_def_mar', 'insur_private', 'insur_other', 'insured',\n",
      "       'decis_personal', 'employment', 'rearnings', 'hincome', 'hinc_business',\n",
      "       'hinc_rent', 'hinc_assets', 'hinc_cap', 'rinc_pension', 'rrelgimp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "missing_percentages = (data_long.isna().sum() / len(data_long)) * 100\n",
    "\n",
    "\n",
    "high_missing_columns = missing_percentages[missing_percentages > 40].index\n",
    "\n",
    "data_long = data_long.drop(columns=high_missing_columns)\n",
    "\n",
    "\n",
    "print(\"Columns remaining after dropping those with more than 40% missing values:\")\n",
    "print(data_long.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after imputation:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imputer_numeric = SimpleImputer(strategy='median')\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\n",
    "numeric_data_imputed = pd.DataFrame(imputer_numeric.fit_transform(numeric_data), columns=numeric_data.columns)\n",
    "categorical_data_imputed = pd.DataFrame(imputer_categorical.fit_transform(categorical_data), columns=categorical_data.columns)\n",
    "\n",
    "\n",
    "data_long_imputed = pd.concat([numeric_data_imputed, categorical_data_imputed], axis=1)\n",
    "\n",
    "\n",
    "print(\"Number of missing values after imputation:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(data_long_imputed.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>composite_score</th>\n",
       "      <th>time</th>\n",
       "      <th>seg_pop_12</th>\n",
       "      <th>comms_tel_comp_12</th>\n",
       "      <th>tv_12</th>\n",
       "      <th>vax_flu_12</th>\n",
       "      <th>table_games_12</th>\n",
       "      <th>satis_excel_12</th>\n",
       "      <th>volunteer_12</th>\n",
       "      <th>...</th>\n",
       "      <th>hinc_cap</th>\n",
       "      <th>rinc_pension</th>\n",
       "      <th>sinc_pension</th>\n",
       "      <th>rrelgimp</th>\n",
       "      <th>rrfcntx_m</th>\n",
       "      <th>rsocact_m</th>\n",
       "      <th>rrelgwk</th>\n",
       "      <th>a34</th>\n",
       "      <th>j11</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aanz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>aanz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aape</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  composite_score  time  seg_pop_12  comms_tel_comp_12  tv_12  \\\n",
       "0  2021.0            175.0   3.0         1.0                0.0    1.0   \n",
       "1  2021.0            175.0  12.0         1.0                0.0    1.0   \n",
       "2  2021.0            206.0   3.0         0.0                0.0    1.0   \n",
       "3  2021.0            206.0  12.0         0.0                0.0    1.0   \n",
       "4  2016.0            161.0   3.0         0.0                1.0    1.0   \n",
       "\n",
       "   vax_flu_12  table_games_12  satis_excel_12  volunteer_12  ...  hinc_cap  \\\n",
       "0         0.0             0.0             3.0           0.0  ...       0.0   \n",
       "1         0.0             0.0             3.0           0.0  ...   10000.0   \n",
       "2         1.0             0.0             2.0           0.0  ...       0.0   \n",
       "3         1.0             0.0             2.0           0.0  ...       0.0   \n",
       "4         0.0             0.0             1.0           0.0  ...       0.0   \n",
       "\n",
       "   rinc_pension  sinc_pension  rrelgimp  rrfcntx_m  rsocact_m  rrelgwk  a34  \\\n",
       "0           0.0           0.0       1.0        4.0        8.0      0.0  2.0   \n",
       "1           0.0           0.0       2.0        9.0        9.0      0.0  2.0   \n",
       "2           0.0           0.0       1.0        4.0        8.0      0.0  2.0   \n",
       "3           0.0           0.0       1.0        9.0        1.0      0.0  2.0   \n",
       "4           0.0           0.0       1.0        4.0        8.0      0.0  2.0   \n",
       "\n",
       "   j11   uid  \n",
       "0  1.0  aace  \n",
       "1  2.0  aace  \n",
       "2  1.0  aanz  \n",
       "3  2.0  aanz  \n",
       "4  1.0  aape  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_long_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('O')], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_long_imputed.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: year - Unique values: [2021. 2016.]\n",
      "Column: composite_score - Unique values: [175. 206. 161. 144. 104. 183. 106. 152.  13. 193.  38. 272. 254.  87.\n",
      "  92. 203. 117.  84.  17.  48.  93. 140.  69. 218.  78. 122. 157. 162.\n",
      "  40. 126. 178. 137.  76. 202.  86. 133. 225. 131. 231. 154.  71.  64.\n",
      " 118. 151. 127. 163. 179. 198. 108. 119.  91. 107. 174. 120.  66.  56.\n",
      " 246. 195. 281. 289. 159. 121. 200. 248. 258. 191. 209.  39. 267. 247.\n",
      " 150. 223. 226. 205. 158. 185.  60. 146. 167.  63. 204.  52. 181. 220.\n",
      " 215. 229.  97. 234. 232. 115.  54. 103. 186. 256.  99. 171.  51.  47.\n",
      " 124. 147.  68. 130. 136. 148. 311. 134. 153. 100. 221. 199.  14.  42.\n",
      " 143.  25. 164.  74.  20. 216.   4. 235. 141. 264. 269. 173. 155. 125.\n",
      " 165. 194. 214. 277.  65. 184. 212. 210. 102.  53.  21.  57.  89.  80.\n",
      " 101. 245. 236.  26. 105. 251.  88. 197.  95. 213. 109. 169. 189.  50.\n",
      "  45. 240. 135. 177. 252. 156. 145. 176. 149. 116. 170.  98. 201. 237.\n",
      " 129. 139. 196.  90. 211. 142.  75.  72.  22. 166. 113.  30. 187. 244.\n",
      " 111. 160. 217. 222.  62.  73. 238.  43. 307. 250. 219. 207. 110.  23.\n",
      "  96.  29.  79. 190.  34. 285. 257.  85.  32. 294. 114. 172. 224. 253.\n",
      " 112. 298. 295. 132.  55.  27.  19. 180. 243.  94.  10. 128.  83. 271.\n",
      " 290.  59. 188.  46. 138.  82. 123. 260. 208. 239. 241.  70. 306. 265.\n",
      "   8. 266. 233. 275.  15. 230. 182. 268. 305. 262.  24. 255. 263.  81.\n",
      " 278. 274. 228. 242.  67. 287.  44. 273.  37. 168. 276. 270. 293.  12.\n",
      " 288. 249.  33. 292. 227.  77.  41. 308. 192.  16.  61.  18.  36. 286.\n",
      "  58.  49.  35. 261. 283.  31. 320. 299. 332. 259.  28. 330. 312. 280.\n",
      " 282. 316. 302. 303. 325. 333. 309. 304. 296. 317. 334. 331. 279.]\n",
      "Column: time - Unique values: [ 3. 12.]\n",
      "Column: seg_pop_12 - Unique values: [1. 0.]\n",
      "Column: comms_tel_comp_12 - Unique values: [0. 1.]\n",
      "Column: tv_12 - Unique values: [1. 0.]\n",
      "Column: vax_flu_12 - Unique values: [0. 1.]\n",
      "Column: table_games_12 - Unique values: [0. 1.]\n",
      "Column: satis_excel_12 - Unique values: [3. 2. 1.]\n",
      "Column: volunteer_12 - Unique values: [0. 1.]\n",
      "Column: sgender_03 - Unique values: [1. 2.]\n",
      "Column: wouldnt_change_12 - Unique values: [3. 1. 2.]\n",
      "Column: attends_club_12 - Unique values: [0. 1.]\n",
      "Column: reads_12 - Unique values: [1. 0.]\n",
      "Column: ragender - Unique values: [1. 2.]\n",
      "Column: care_child_12 - Unique values: [0. 1.]\n",
      "Column: satis_ideal_12 - Unique values: [3. 1. 2.]\n",
      "Column: games_12 - Unique values: [0. 1.]\n",
      "Column: satis_fine_12 - Unique values: [1. 3. 2.]\n",
      "Column: a22_12 - Unique values: [1. 3. 2. 8. 4. 5. 7.]\n",
      "Column: attends_class_12 - Unique values: [0. 1.]\n",
      "Column: act_mant_12 - Unique values: [1. 0.]\n",
      "Column: cosas_imp_12 - Unique values: [1. 2. 3.]\n",
      "Column: a16a_12 - Unique values: [1972. 1978. 1987. 1965. 1960. 1970. 1951. 2002. 1975. 1993. 2012. 1962.\n",
      " 1976. 2010. 2005. 1957. 1945. 1985. 1942. 1964. 1958. 1969. 1968. 1974.\n",
      " 1940. 2011. 1997.]\n",
      "Column: vax_pneu_12 - Unique values: [0. 1.]\n",
      "Column: memory_12 - Unique values: [2. 4. 3. 5. 1.]\n",
      "Column: a33b_12 - Unique values: [3. 1. 2.]\n",
      "Column: sewing_12 - Unique values: [0. 1.]\n",
      "Column: a21_12 - Unique values: [ 2.  1. 52.  3. 40. 15.  7. 30.  4.  5.  6. 36. 10. 27. 34. 32. 12.]\n",
      "Column: sgender_12 - Unique values: [2. 1.]\n",
      "Column: care_adult_12 - Unique values: [0. 1.]\n",
      "Column: rameduc_m - Unique values: [1. 2. 3. 4.]\n",
      "Column: rafeduc_m - Unique values: [1. 2. 4. 3.]\n",
      "Column: age - Unique values: [2. 1. 3. 4. 0.]\n",
      "Column: urban - Unique values: [1. 0.]\n",
      "Column: married - Unique values: [1. 3. 2. 4.]\n",
      "Column: n_mar - Unique values: [1. 2. 3. 4. 0. 5. 7.]\n",
      "Column: edu_gru - Unique values: [1. 0. 3. 2. 4.]\n",
      "Column: n_living_child - Unique values: [2. 1. 3. 0. 4.]\n",
      "Column: migration - Unique values: [0. 1.]\n",
      "Column: glob_hlth - Unique values: [4. 5. 3. 2. 1.]\n",
      "Column: adl_dress - Unique values: [0. 1.]\n",
      "Column: adl_walk - Unique values: [0. 1.]\n",
      "Column: adl_bath - Unique values: [0. 1.]\n",
      "Column: adl_eat - Unique values: [0. 1.]\n",
      "Column: adl_bed - Unique values: [0. 1.]\n",
      "Column: adl_toilet - Unique values: [0. 1.]\n",
      "Column: n_adl - Unique values: [0. 1. 3. 2. 5. 4.]\n",
      "Column: iadl_money - Unique values: [0. 1.]\n",
      "Column: iadl_meds - Unique values: [0. 1.]\n",
      "Column: iadl_shop - Unique values: [0. 1.]\n",
      "Column: iadl_meals - Unique values: [0. 1.]\n",
      "Column: n_iadl - Unique values: [0. 1. 2. 3. 4.]\n",
      "Column: depressed - Unique values: [0. 1.]\n",
      "Column: hard - Unique values: [0. 1.]\n",
      "Column: restless - Unique values: [0. 1.]\n",
      "Column: happy - Unique values: [1. 0.]\n",
      "Column: lonely - Unique values: [0. 1.]\n",
      "Column: enjoy - Unique values: [1. 0.]\n",
      "Column: sad - Unique values: [0. 1.]\n",
      "Column: tired - Unique values: [1. 0.]\n",
      "Column: energetic - Unique values: [0. 1.]\n",
      "Column: n_depr - Unique values: [3. 0. 4. 6. 8. 5. 7. 9. 2. 1.]\n",
      "Column: cesd_depressed - Unique values: [0. 1.]\n",
      "Column: hypertension - Unique values: [0. 1.]\n",
      "Column: diabetes - Unique values: [0. 1.]\n",
      "Column: resp_ill - Unique values: [0. 1.]\n",
      "Column: arthritis - Unique values: [0. 1.]\n",
      "Column: hrt_attack - Unique values: [0. 1.]\n",
      "Column: stroke - Unique values: [0. 1.]\n",
      "Column: cancer - Unique values: [0. 1.]\n",
      "Column: n_illnesses - Unique values: [1. 0. 3. 2. 4. 5.]\n",
      "Column: bmi - Unique values: [3. 4. 2. 1. 5.]\n",
      "Column: exer_3xwk - Unique values: [0. 1.]\n",
      "Column: alcohol - Unique values: [0. 1.]\n",
      "Column: tobacco - Unique values: [0. 1.]\n",
      "Column: test_chol - Unique values: [1. 0.]\n",
      "Column: test_tuber - Unique values: [0. 1.]\n",
      "Column: test_diab - Unique values: [1. 0.]\n",
      "Column: test_pres - Unique values: [1. 0.]\n",
      "Column: hosp - Unique values: [0. 1.]\n",
      "Column: visit_med - Unique values: [1. 0.]\n",
      "Column: out_proc - Unique values: [0. 1.]\n",
      "Column: visit_dental - Unique values: [0. 1.]\n",
      "Column: imss - Unique values: [0. 1.]\n",
      "Column: issste - Unique values: [0. 1.]\n",
      "Column: pem_def_mar - Unique values: [0. 1.]\n",
      "Column: insur_private - Unique values: [0. 1.]\n",
      "Column: insur_other - Unique values: [0. 1.]\n",
      "Column: insured - Unique values: [1. 0.]\n",
      "Column: decis_famil - Unique values: [2. 3. 1.]\n",
      "Column: decis_personal - Unique values: [1. 2. 3.]\n",
      "Column: employment - Unique values: [3. 1. 2. 4.]\n",
      "Column: rjob_hrswk - Unique values: [ 42.  66.  72.  60.  30.  48.  35.  24.   5.  19.  36.  45.  39.  63.\n",
      "  56.  55.  12.  84.   9.  52.  28.   0.   6.  40.  18.  14.  25.  57.\n",
      "  54.  49.  15.  10.  16.  20.  98.  21.  44.  70.  58.   4.  50.  90.\n",
      "  93.  47.  61.   8.  46.  99.  87.  64.  77.  96.  91.  13.   3.  65.\n",
      "  26.  67.   7.  38.  59.  94.  23.  51.  81.  43.  68.  29.  34.  33.\n",
      "  53.  71.  73.  37.  31.  76. 111.  32.  41.  27.  22.  74.  79.  80.\n",
      "  62.  82.  69.  11.  97.  88. 109.  85.   1.  83.  78. 105. 168.  17.\n",
      "  75.  86. 119. 112.]\n",
      "Column: rjlocc_m - Unique values: [11.  6. 18.  8. 14. 17.  9. 15. 16.  4.  3. 12. 10.  1. 13.  7.  2. 19.\n",
      "  5.]\n",
      "Column: rjob_end - Unique values: [1996. 2003. 2007. 1973. 1962. 2010. 2012. 1995. 1987. 2005. 1967. 2008.\n",
      " 1993. 2001. 2002. 1950. 2004. 1994. 1953. 1949. 1991. 1985. 2000. 1978.\n",
      " 1992. 1997. 1989. 1963. 2011. 1999. 1952. 1984. 1980. 1971. 1969. 1968.\n",
      " 1988. 1964. 2006. 1960. 1946. 2009. 1998. 1958. 1990. 1986. 1959. 1983.\n",
      " 1972. 1961. 1981. 1970. 1979. 1982. 1951. 1977. 1965. 1974. 1945. 1941.\n",
      " 1954. 1948. 1935. 1947. 1943. 1955. 1975. 1944. 1976. 1956. 1966. 1957.\n",
      " 1937. 1933.]\n",
      "Column: rjobend_reason - Unique values: [4. 8. 5. 3. 1.]\n",
      "Column: rearnings - Unique values: [0.00e+00 7.00e+04 1.00e+04 3.00e+04 5.00e+04 2.00e+04 6.00e+04 1.90e+04\n",
      " 1.00e+05 4.80e+04 6.00e+03 2.90e+05 1.08e+05 8.00e+04 6.80e+04 8.00e+03\n",
      " 5.80e+04 2.60e+05 1.50e+05 2.60e+04 2.10e+04 5.20e+04 4.00e+04 3.60e+04\n",
      " 1.20e+04 4.10e+04 5.00e+03 2.40e+04 2.50e+04 4.40e+04 1.30e+05 1.30e+04\n",
      " 3.00e+03 1.10e+04 1.90e+05 3.50e+04 1.12e+05 8.70e+04 1.10e+05 3.90e+04\n",
      " 2.20e+04 5.60e+04 1.40e+04 9.80e+04 1.70e+04 2.90e+04 3.80e+04 3.40e+04\n",
      " 1.20e+05 1.03e+06 7.90e+04 5.10e+04 3.10e+04 9.00e+04 7.00e+03 7.20e+04\n",
      " 4.60e+05 5.40e+04 4.30e+04 6.50e+04 7.80e+04 2.00e+05 3.60e+05 6.30e+04\n",
      " 1.98e+05 9.40e+04 4.90e+04 1.40e+05 8.80e+04 4.30e+05 3.00e+05 4.00e+03\n",
      " 1.80e+04 1.80e+05 1.49e+05 1.87e+05 9.00e+03 6.10e+04 7.60e+04 6.60e+04\n",
      " 1.56e+05 1.00e+03 6.70e+04 1.96e+05 2.16e+05 1.59e+05 2.22e+05 1.02e+05\n",
      " 2.70e+04 1.60e+04 1.57e+05 1.28e+05 2.40e+05 8.10e+05 7.70e+04 5.30e+04\n",
      " 1.14e+05 2.48e+05 6.90e+04 9.50e+04 1.70e+05 1.51e+05 3.84e+05 3.70e+04\n",
      " 2.45e+05 4.20e+04 7.10e+04 9.60e+04 1.16e+06 1.62e+05 3.30e+04 8.90e+04\n",
      " 2.28e+05 1.74e+05 1.63e+05 1.25e+05 2.50e+05 4.60e+04 2.30e+04 1.50e+04\n",
      " 6.20e+04 3.20e+04 6.10e+05 7.50e+04 7.30e+04 5.80e+05 4.70e+04 7.40e+05\n",
      " 8.50e+04 6.40e+04 2.70e+05 2.20e+05 4.50e+04 2.32e+05 7.40e+04 8.40e+04\n",
      " 2.80e+05 1.86e+05 1.54e+05 1.64e+05 2.80e+04 9.10e+04 7.20e+05 2.12e+05\n",
      " 5.70e+04 4.20e+05 6.90e+05 1.38e+05 8.60e+04 3.08e+05 6.80e+05 5.90e+04\n",
      " 9.20e+04 1.60e+05 2.00e+03 8.30e+04 2.10e+05 1.76e+05 1.89e+05 1.94e+05\n",
      " 2.37e+05 3.10e+05 2.08e+05 1.27e+05 5.50e+04 2.54e+05 8.10e+04 1.09e+05\n",
      " 1.07e+05 1.82e+05 3.40e+05 1.68e+05 1.00e+06 7.50e+05 2.75e+05]\n",
      "Column: searnings - Unique values: [      0.  160000.  100000.   20000.   60000.   30000.   50000.   10000.\n",
      "   70000.  150000.   80000.  200000. 1370000.   40000.  120000.  300000.\n",
      "  140000.  110000.  360000.  210000.  240000.  130000.   90000.  570000.\n",
      "  180000.  190000.  250000.  220000.  790000.  450000.  170000.  350000.\n",
      "  320000.  260000.  530000.  280000.  270000.  610000.  430000.  310000.\n",
      " 1030000.  960000.  680000. 1020000.]\n",
      "Column: hincome - Unique values: [ 2.000e+04  1.400e+05  7.000e+04  0.000e+00  1.000e+04  3.000e+04\n",
      "  8.000e+04 -3.000e+04  1.600e+05  1.300e+05  6.000e+04  2.500e+05\n",
      "  1.000e+05  4.600e+05  1.100e+05  5.000e+04  1.700e+05  4.000e+04\n",
      "  9.000e+04  1.200e+05 -1.000e+04  2.900e+05  2.550e+06  5.800e+05\n",
      "  1.520e+06  1.800e+05  5.000e+05  3.600e+05  9.100e+05  2.700e+05\n",
      "  2.800e+05  6.900e+05  1.500e+05  3.300e+05  1.900e+05  1.060e+06\n",
      "  2.300e+05  2.150e+06  2.400e+05  3.100e+05  3.200e+05  9.000e+05\n",
      "  2.000e+05  1.030e+06  3.000e+05  2.200e+05  8.900e+05  9.900e+05\n",
      "  6.200e+05  8.200e+05  4.700e+05  2.600e+05  3.700e+05  4.100e+05\n",
      "  3.800e+05  1.230e+06  2.100e+05  4.000e+05  1.200e+06  6.100e+05\n",
      "  1.110e+06  4.900e+05  8.700e+05  1.080e+06  7.200e+05  4.300e+05\n",
      "  3.400e+05  5.700e+05  3.500e+05  7.600e+05  1.810e+06  6.000e+05\n",
      "  1.310e+06 -1.900e+05  4.200e+05  2.050e+06  9.800e+05  3.602e+07\n",
      "  7.900e+05  1.050e+06  2.400e+06  7.000e+05  4.800e+05  1.000e+06\n",
      "  1.170e+06  4.500e+05  1.590e+06  6.500e+05  5.200e+05  5.500e+05\n",
      "  6.400e+05  1.650e+06  1.160e+06  1.470e+06  4.400e+05  5.530e+06\n",
      " -1.500e+05  3.900e+05  5.300e+05  2.290e+06  1.420e+06  6.020e+06\n",
      "  1.480e+06 -9.000e+04  6.300e+05  1.210e+06  7.400e+05  1.070e+06\n",
      " -2.000e+04  4.300e+06  5.900e+05  9.600e+05  5.400e+05  1.040e+06\n",
      "  7.100e+05  6.800e+05  1.140e+06  8.600e+05 -5.000e+04  5.100e+05\n",
      "  8.300e+05  6.600e+05  1.440e+06  8.400e+05  6.700e+05  2.270e+06\n",
      " -2.000e+05  1.020e+06  7.800e+05  8.000e+05 -8.000e+04  9.400e+05\n",
      "  7.500e+05  3.630e+06]\n",
      "Column: hinc_business - Unique values: [0.00e+00 1.00e+04 7.00e+04 1.20e+05 2.40e+05 4.60e+05 1.60e+05 1.10e+05\n",
      " 4.00e+04 3.00e+04 2.00e+04 1.00e+05 1.80e+05 4.90e+05 3.60e+05 9.10e+05\n",
      " 8.00e+04 5.80e+05 6.00e+04 2.30e+05 1.05e+06 5.00e+04 1.32e+06 8.40e+05\n",
      " 3.30e+05 1.50e+05 1.30e+05 2.80e+05 2.00e+05 8.90e+05 9.70e+05 8.00e+05\n",
      " 4.10e+05 1.90e+05 4.00e+05 9.00e+04 4.30e+05 1.07e+06 7.20e+05 2.20e+05\n",
      " 1.80e+06 1.27e+06 2.05e+06 1.40e+05 3.60e+07 1.70e+05 6.90e+05 9.80e+05\n",
      " 4.40e+05 1.38e+06 1.59e+06 3.50e+05 6.00e+05 1.43e+06 3.80e+05 9.90e+05\n",
      " 3.70e+05 1.20e+06 2.29e+06 8.70e+05 4.80e+05 7.90e+05 1.37e+06 1.02e+06\n",
      " 7.50e+05 5.60e+05 9.60e+05 5.70e+05 3.00e+05 1.52e+06 5.90e+05 5.40e+05\n",
      " 7.10e+05 1.14e+06 6.20e+05 2.50e+05 6.10e+05 5.30e+05 6.50e+05 1.65e+06\n",
      " 1.44e+06 6.60e+05 2.24e+06 8.30e+05 7.60e+05 9.40e+05]\n",
      "Column: hinc_rent - Unique values: [      0.  -60000.  -10000.   20000.   90000.   60000.   10000.  820000.\n",
      "  300000.  900000.  -30000.   40000.  220000.  -40000.  340000.  840000.\n",
      " -360000.   50000.   80000.   30000.  -20000. -210000.  420000. 1200000.\n",
      "  -50000.  130000.  100000. -160000.  140000. -140000.  120000.  540000.\n",
      " -170000. -100000. -120000.  400000.  170000.  160000.  110000. -180000.\n",
      "  -80000.   70000.  200000. -200000.  710000.  600000.]\n",
      "Column: hinc_assets - Unique values: [     0.   8000. 232000.  18000.   1000.   2000.  14000.  22000.   6000.\n",
      "  10000.  91000.  11000.   5000.  19000.  24000.  89000.  12000.   4000.\n",
      "  31000. 129000.  93000.  15000.   3000.  40000.   9000. 105000.  72000.\n",
      "  36000.  13000.  26000.  41000. 103000.  16000. 180000.   7000.  27000.\n",
      "  20000.  17000.  73000.  98000.  25000.  74000.  42000.  60000. 360000.\n",
      "  84000.  77000.]\n",
      "Column: hinc_cap - Unique values: [ 0.00e+00  1.00e+04  7.00e+04 -6.00e+04  1.20e+05  2.40e+05  4.60e+05\n",
      "  1.60e+05  1.10e+05  4.00e+04 -1.00e+04  3.00e+04  2.00e+04  9.00e+04\n",
      "  6.00e+04  1.00e+05  1.80e+05  4.90e+05  3.60e+05  9.10e+05  2.30e+05\n",
      "  8.00e+04  5.80e+05  1.05e+06  5.00e+04  2.15e+06  3.00e+05  9.00e+05\n",
      " -3.00e+04  8.40e+05  3.30e+05  1.50e+05  1.30e+05  2.80e+05  2.00e+05\n",
      "  8.90e+05  9.70e+05  8.00e+05  4.10e+05  2.20e+05  1.90e+05  4.00e+05\n",
      " -4.00e+04  3.40e+05  4.30e+05  1.07e+06  1.80e+06 -2.00e+04  1.27e+06\n",
      " -2.10e+05  4.20e+05  1.20e+06  2.05e+06  1.40e+05  3.80e+05  3.60e+07\n",
      "  1.70e+05  6.90e+05  9.80e+05  4.40e+05  1.22e+06  1.59e+06  3.50e+05\n",
      "  6.00e+05  1.43e+06 -1.40e+05  9.90e+05 -1.70e+05  3.70e+05  2.29e+06\n",
      "  8.70e+05  4.80e+05  7.90e+05  1.37e+06  1.02e+06  7.50e+05  5.60e+05\n",
      "  1.46e+06  9.60e+05 -1.20e+05  7.20e+05  5.70e+05 -5.00e+04  1.52e+06\n",
      "  5.90e+05  5.40e+05  7.10e+05  2.70e+05  1.14e+06  2.10e+05  6.20e+05\n",
      "  2.50e+05  6.10e+05  5.30e+05  6.50e+05  1.65e+06  1.44e+06  6.60e+05\n",
      "  2.24e+06 -2.00e+05  8.30e+05  7.70e+05 -8.00e+04  9.40e+05]\n",
      "Column: rinc_pension - Unique values: [     0.  16000.  30000. 170000.  20000.  10000.  70000.  72000.  34000.\n",
      "  60000. 120000.  50000.  80000.  14000.  55000.  17000.  24000.  40000.\n",
      "  13000.  18000.  36000. 100000.  22000.  19000.  82000.  23000. 200000.\n",
      "  98000. 130000.   8000.  96000. 168000. 108000.  83000.  12000.  48000.\n",
      " 180000.  71000. 150000.   7000. 240000.  76000. 110000. 264000. 720000.\n",
      "  84000.  42000. 220000.  51000.  11000. 144000. 260000.  54000. 360000.\n",
      " 600000. 960000. 140000. 480000.  33000. 190000.  26000.  41000.  44000.\n",
      "   4000.   2000. 430000.   3000.  90000.  35000. 250000. 137000.  46000.\n",
      "  15000. 156000. 230000.  61000.  49000.  28000. 158000. 160000. 310000.\n",
      "   6000.  31000.  25000.  64000.  58000.  32000.  52000.  38000. 320000.\n",
      " 290000.  66000.  29000.  85000. 149000. 300000.   5000. 114000.  73000.\n",
      " 204000. 340000.]\n",
      "Column: sinc_pension - Unique values: [      0.   38000.   30000.   14000.   40000.   10000.  120000.   20000.\n",
      "   80000.   25000.   16000.  240000.   60000.   22000.   96000.   17000.\n",
      "   35000.   18000.  200000.    2000.  100000.   84000.   70000.  216000.\n",
      "   28000.   24000.   12000.   48000.  180000.   41000.   54000.   50000.\n",
      "   13000.   11000.  144000.   72000.  480000.  190000.  140000.   81000.\n",
      "  130000.   23000.  160000.  110000.   76000.  170000.  108000.   42000.\n",
      "  340000.  150000.   49000.    5000.   29000.   97000.   36000.  114000.\n",
      "   19000.  132000. 1200000.   58000.   44000.  127000.   31000.  168000.\n",
      "   15000.   90000.  220000.  156000.  204000.  360000.   32000.  115000.\n",
      "  109000.   66000.  260000.  185000.  280000.    8000.  600000.  230000.\n",
      "   21000.  192000.   98000.   61000.   52000.   34000. 1080000.  228000.]\n",
      "Column: rrelgimp - Unique values: [1. 2. 3.]\n",
      "Column: rrfcntx_m - Unique values: [4. 9. 6. 3. 8. 1. 2. 7. 5.]\n",
      "Column: rsocact_m - Unique values: [8. 9. 1. 2. 3. 4. 7. 6. 5.]\n",
      "Column: rrelgwk - Unique values: [0. 1.]\n",
      "Column: a34 - Unique values: [2. 1.]\n",
      "Column: j11 - Unique values: [1. 2. 3.]\n",
      "Column: uid - Unique values: ['aace' 'aanz' 'aape' ... 'zzez' 'zzft' 'zzhd']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_values = data_long_imputed.apply(lambda x: x.unique())\n",
    "\n",
    "\n",
    "for col, unique_vals in unique_values.items():\n",
    "    print(f\"Column: {col} - Unique values: {unique_vals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  composite_score  time  seg_pop_12  comms_tel_comp_12  tv_12  \\\n",
      "0  2021.0            175.0   3.0         1.0                0.0    1.0   \n",
      "1  2021.0            175.0  12.0         1.0                0.0    1.0   \n",
      "2  2021.0            206.0   3.0         0.0                0.0    1.0   \n",
      "3  2021.0            206.0  12.0         0.0                0.0    1.0   \n",
      "4  2016.0            161.0   3.0         0.0                1.0    1.0   \n",
      "\n",
      "   vax_flu_12  table_games_12  satis_excel_12  volunteer_12  ...  uid_zytb  \\\n",
      "0         0.0             0.0             3.0           0.0  ...     False   \n",
      "1         0.0             0.0             3.0           0.0  ...     False   \n",
      "2         1.0             0.0             2.0           0.0  ...     False   \n",
      "3         1.0             0.0             2.0           0.0  ...     False   \n",
      "4         0.0             0.0             1.0           0.0  ...     False   \n",
      "\n",
      "   uid_zyxh  uid_zzab  uid_zzag  uid_zzci  uid_zzez  uid_zzft  uid_zzhd  \\\n",
      "0     False     False     False     False     False     False     False   \n",
      "1     False     False     False     False     False     False     False   \n",
      "2     False     False     False     False     False     False     False   \n",
      "3     False     False     False     False     False     False     False   \n",
      "4     False     False     False     False     False     False     False   \n",
      "\n",
      "   uid_zzjb  uid_zzti  \n",
      "0     False     False  \n",
      "1     False     False  \n",
      "2     False     False  \n",
      "3     False     False  \n",
      "4     False     False  \n",
      "\n",
      "[5 rows x 4207 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_long_imputed = pd.get_dummies(data_long_imputed, columns=['uid'])\n",
    "\n",
    "\n",
    "print(data_long_imputed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_long_imputed.drop(columns=['composite_score'])  # Drop target and any non-feature columns\n",
    "y = data_long_imputed['composite_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X,y , test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_y_pred = lr_model.predict(X_test)\n",
    "\n",
    "lr_results = {\n",
    "    'Model': 'Linear Regression',\n",
    "    'MAE': mean_absolute_error(y_test, lr_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, lr_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, lr_y_pred)),\n",
    "    'R-squared': r2_score(y_test, lr_y_pred)\n",
    "}\n",
    "model_results.append(lr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge_model = Ridge()\n",
    "ridge_param_grid = {'alpha': [0.1, 1.0, 10]}\n",
    "ridge_grid_search = GridSearchCV(ridge_model, ridge_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "ridge_best_model = ridge_grid_search.best_estimator_\n",
    "ridge_y_pred = ridge_best_model.predict(X_test)\n",
    "\n",
    "ridge_results = {\n",
    "    'Model': 'Ridge',\n",
    "    'Best Parameters': ridge_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, ridge_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, ridge_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, ridge_y_pred)),\n",
    "    'R-squared': r2_score(y_test, ridge_y_pred)\n",
    "}\n",
    "model_results.append(ridge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso_model = Lasso()\n",
    "lasso_param_grid = {'alpha': [0.1, 1.0, 10]}\n",
    "lasso_grid_search = GridSearchCV(lasso_model, lasso_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "lasso_best_model = lasso_grid_search.best_estimator_\n",
    "lasso_y_pred = lasso_best_model.predict(X_test)\n",
    "\n",
    "lasso_results = {\n",
    "    'Model': 'Lasso',\n",
    "    'Best Parameters': lasso_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, lasso_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, lasso_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, lasso_y_pred)),\n",
    "    'R-squared': r2_score(y_test, lasso_y_pred)\n",
    "}\n",
    "model_results.append(lasso_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet Regression\n",
    "en_model = ElasticNet()\n",
    "en_param_grid = {'alpha': [0.1, 1.0, 10], 'l1_ratio': [0.2, 0.5, 0.8]}\n",
    "en_grid_search = GridSearchCV(en_model, en_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "en_grid_search.fit(X_train, y_train)\n",
    "en_best_model = en_grid_search.best_estimator_\n",
    "en_y_pred = en_best_model.predict(X_test)\n",
    "\n",
    "en_results = {\n",
    "    'Model': 'ElasticNet',\n",
    "    'Best Parameters': en_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, en_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, en_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, en_y_pred)),\n",
    "    'R-squared': r2_score(y_test, en_y_pred)\n",
    "}\n",
    "model_results.append(en_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree Regressor\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_param_grid = {'max_depth': [5, 10, None], 'min_samples_split': [2, 5]}\n",
    "dt_grid_search = GridSearchCV(dt_model, dt_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "dt_best_model = dt_grid_search.best_estimator_\n",
    "dt_y_pred = dt_best_model.predict(X_test)\n",
    "\n",
    "dt_results = {\n",
    "    'Model': 'DecisionTree',\n",
    "    'Best Parameters': dt_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, dt_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, dt_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, dt_y_pred)),\n",
    "    'R-squared': r2_score(y_test, dt_y_pred)\n",
    "}\n",
    "model_results.append(dt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_param_grid = {'n_estimators': [50, 100], 'max_depth': [5, 10, None]}\n",
    "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "rf_y_pred = rf_best_model.predict(X_test)\n",
    "\n",
    "rf_results = {\n",
    "    'Model': 'Random Forest',\n",
    "    'Best Parameters': rf_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, rf_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, rf_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, rf_y_pred)),\n",
    "    'R-squared': r2_score(y_test, rf_y_pred)\n",
    "}\n",
    "model_results.append(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "gb_grid_search = GridSearchCV(gb_model, gb_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "gb_best_model = gb_grid_search.best_estimator_\n",
    "gb_y_pred = gb_best_model.predict(X_test)\n",
    "\n",
    "gb_results = {\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'Best Parameters': gb_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, gb_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, gb_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, gb_y_pred)),\n",
    "    'R-squared': r2_score(y_test, gb_y_pred)\n",
    "}\n",
    "model_results.append(gb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regression\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.05, 0.1]}\n",
    "xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "xgb_best_model = xgb_grid_search.best_estimator_\n",
    "xgb_y_pred = xgb_best_model.predict(X_test)\n",
    "\n",
    "xgb_results = {\n",
    "    'Model': 'XGBoost',\n",
    "    'Best Parameters': xgb_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, xgb_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, xgb_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, xgb_y_pred)),\n",
    "    'R-squared': r2_score(y_test, xgb_y_pred)\n",
    "}\n",
    "model_results.append(xgb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 7226, number of used features: 111\n",
      "[LightGBM] [Info] Start training from score 157.145862\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Regression\n",
    "lgbm_model = LGBMRegressor()\n",
    "lgbm_param_grid = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1]}\n",
    "lgbm_grid_search = GridSearchCV(lgbm_model, lgbm_param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "lgbm_grid_search.fit(X_train, y_train)\n",
    "lgbm_best_model = lgbm_grid_search.best_estimator_\n",
    "lgbm_y_pred = lgbm_best_model.predict(X_test)\n",
    "\n",
    "lgbm_results = {\n",
    "    'Model': 'LightGBM',\n",
    "    'Best Parameters': lgbm_grid_search.best_params_,\n",
    "    'MAE': mean_absolute_error(y_test, lgbm_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, lgbm_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, lgbm_y_pred)),\n",
    "    'R-squared': r2_score(y_test, lgbm_y_pred)\n",
    "}\n",
    "model_results.append(lgbm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Regression\n",
    "catboost_model = CatBoostRegressor(verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "catboost_y_pred = catboost_model.predict(X_test)\n",
    "\n",
    "catboost_results = {\n",
    "    'Model': 'CatBoost',\n",
    "    'MAE': mean_absolute_error(y_test, catboost_y_pred),\n",
    "    'MSE': mean_squared_error(y_test, catboost_y_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, catboost_y_pred)),\n",
    "    'R-squared': r2_score(y_test, catboost_y_pred)\n",
    "}\n",
    "model_results.append(catboost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'Linear Regression',\n",
       "  'MAE': 14.443170892090407,\n",
       "  'MSE': 661.2595449323884,\n",
       "  'RMSE': 25.71496733290533,\n",
       "  'R-squared': 0.7846370306721786},\n",
       " {'Model': 'Ridge',\n",
       "  'Best Parameters': {'alpha': 0.1},\n",
       "  'MAE': 15.639970190323652,\n",
       "  'MSE': 636.2851862390061,\n",
       "  'RMSE': 25.224693977113102,\n",
       "  'R-squared': 0.7927708293999003},\n",
       " {'Model': 'Lasso',\n",
       "  'Best Parameters': {'alpha': 0.1},\n",
       "  'MAE': 33.710358005506905,\n",
       "  'MSE': 1834.7836462733503,\n",
       "  'RMSE': 42.83437458716247,\n",
       "  'R-squared': 0.40243667231153835},\n",
       " {'Model': 'ElasticNet',\n",
       "  'Best Parameters': {'alpha': 0.1, 'l1_ratio': 0.5},\n",
       "  'MAE': 33.803437171661464,\n",
       "  'MSE': 1848.5305498521022,\n",
       "  'RMSE': 42.9945409308217,\n",
       "  'R-squared': 0.3979594984144327},\n",
       " {'Model': 'DecisionTree',\n",
       "  'Best Parameters': {'max_depth': 5, 'min_samples_split': 2},\n",
       "  'MAE': 35.621103725919184,\n",
       "  'MSE': 2081.7136198825633,\n",
       "  'RMSE': 45.625799936905906,\n",
       "  'R-squared': 0.3220150394745286},\n",
       " {'Model': 'Random Forest',\n",
       "  'Best Parameters': {'max_depth': None, 'n_estimators': 100},\n",
       "  'MAE': 29.837863137508073,\n",
       "  'MSE': 1469.6708980632663,\n",
       "  'RMSE': 38.33628696239721,\n",
       "  'R-squared': 0.5213487790577702},\n",
       " {'Model': 'Gradient Boosting',\n",
       "  'Best Parameters': {'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  'MAE': 33.09612053791795,\n",
       "  'MSE': 1749.7915010940596,\n",
       "  'RMSE': 41.83050921389865,\n",
       "  'R-squared': 0.43011742322943236},\n",
       " {'Model': 'XGBoost',\n",
       "  'Best Parameters': {'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  'MAE': 31.915931731212364,\n",
       "  'MSE': 1631.7593113906516,\n",
       "  'RMSE': 40.39504067816558,\n",
       "  'R-squared': 0.4685588537472931},\n",
       " {'Model': 'LightGBM',\n",
       "  'Best Parameters': {'learning_rate': 0.1, 'n_estimators': 100},\n",
       "  'MAE': 31.413385429644112,\n",
       "  'MSE': 1595.3624095231146,\n",
       "  'RMSE': 39.94198805171213,\n",
       "  'R-squared': 0.48041281475337216},\n",
       " {'Model': 'CatBoost',\n",
       "  'MAE': 31.144867047624924,\n",
       "  'MSE': 1524.810810543648,\n",
       "  'RMSE': 39.04882598163033,\n",
       "  'R-squared': 0.5033904820906311}]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model        MAE          MSE       RMSE  R-squared  \\\n",
      "1              Ridge  15.639970   636.285186  25.224694   0.792771   \n",
      "0  Linear Regression  14.443171   661.259545  25.714967   0.784637   \n",
      "5      Random Forest  29.837863  1469.670898  38.336287   0.521349   \n",
      "9           CatBoost  31.144867  1524.810811  39.048826   0.503390   \n",
      "8           LightGBM  31.413385  1595.362410  39.941988   0.480413   \n",
      "7            XGBoost  31.915932  1631.759311  40.395041   0.468559   \n",
      "6  Gradient Boosting  33.096121  1749.791501  41.830509   0.430117   \n",
      "2              Lasso  33.710358  1834.783646  42.834375   0.402437   \n",
      "3         ElasticNet  33.803437  1848.530550  42.994541   0.397959   \n",
      "4       DecisionTree  35.621104  2081.713620  45.625800   0.322015   \n",
      "\n",
      "                               Best Parameters  \n",
      "1                               {'alpha': 0.1}  \n",
      "0                                          NaN  \n",
      "5     {'max_depth': None, 'n_estimators': 100}  \n",
      "9                                          NaN  \n",
      "8  {'learning_rate': 0.1, 'n_estimators': 100}  \n",
      "7  {'learning_rate': 0.1, 'n_estimators': 100}  \n",
      "6  {'learning_rate': 0.1, 'n_estimators': 100}  \n",
      "2                               {'alpha': 0.1}  \n",
      "3              {'alpha': 0.1, 'l1_ratio': 0.5}  \n",
      "4     {'max_depth': 5, 'min_samples_split': 2}  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(model_results)\n",
    "\n",
    "results_df = results_df.sort_values(by='RMSE', ascending=True)\n",
    "\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('best_ridge_model.pkl', 'wb') as file:\n",
    "    pickle.dump(ridge_best_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
