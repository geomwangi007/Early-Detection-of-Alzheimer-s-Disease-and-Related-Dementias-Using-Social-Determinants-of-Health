{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import streamlit as st\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "test_data = pd.read_csv('C:/Users/Hp/Desktop/Capstone Project/Data/test_features.csv')\n",
    "train_data = pd.read_csv('C:/Users/Hp/Desktop/Capstone Project/Data/train_features.csv')\n",
    "train_labels = pd.read_csv('C:/Users/Hp/Desktop/Capstone Project/Data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 819 entries, 0 to 818\n",
      "Columns: 184 entries, uid to j11_12\n",
      "dtypes: float64(140), object(44)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "         n_mar_03  migration_03  adl_dress_03  adl_walk_03  adl_bath_03  \\\n",
      "count  568.000000    570.000000    542.000000   569.000000   569.000000   \n",
      "mean     1.165493      0.077193      0.047970     0.012302     0.012302   \n",
      "std      0.535254      0.267132      0.213901     0.110328     0.110328   \n",
      "min      0.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "25%      1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "50%      1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "75%      1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "max      4.000000      1.000000      1.000000     1.000000     1.000000   \n",
      "\n",
      "       adl_eat_03  adl_bed_03  adl_toilet_03    n_adl_03  iadl_money_03  ...  \\\n",
      "count  569.000000  569.000000     569.000000  569.000000     542.000000  ...   \n",
      "mean     0.005272    0.038664       0.019332    0.087873       0.009225  ...   \n",
      "std      0.072483    0.192963       0.137811    0.443272       0.095692  ...   \n",
      "min      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "25%      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "50%      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "75%      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "max      1.000000    1.000000       1.000000    5.000000       1.000000  ...   \n",
      "\n",
      "        searnings_12    hincome_12  hinc_business_12   hinc_rent_12  \\\n",
      "count     508.000000  7.730000e+02      7.940000e+02     794.000000   \n",
      "mean    10196.850394  6.608021e+04      1.010076e+04    2216.624685   \n",
      "std     35871.244519  2.540155e+05      7.190606e+04   35284.803065   \n",
      "min         0.000000 -2.000000e+05      0.000000e+00 -200000.000000   \n",
      "25%         0.000000  0.000000e+00      0.000000e+00       0.000000   \n",
      "50%         0.000000  2.000000e+04      0.000000e+00       0.000000   \n",
      "75%         0.000000  5.000000e+04      0.000000e+00       0.000000   \n",
      "max    310000.000000  6.020000e+06      1.430000e+06  710000.000000   \n",
      "\n",
      "       hinc_assets_12   hinc_cap_12  rinc_pension_12  sinc_pension_12  \\\n",
      "count      794.000000  7.940000e+02       794.000000     5.080000e+02   \n",
      "mean       367.758186  1.265743e+04     13476.070529     1.039370e+04   \n",
      "std       4482.643368  8.003225e+04     38708.762304     5.315530e+04   \n",
      "min          0.000000 -2.000000e+05         0.000000     0.000000e+00   \n",
      "25%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "50%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "75%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "max      84000.000000  1.430000e+06    480000.000000     1.080000e+06   \n",
      "\n",
      "           a16a_12     a21_12  \n",
      "count     6.000000  11.000000  \n",
      "mean   1975.833333   6.454545  \n",
      "std      25.103121   9.771015  \n",
      "min    1940.000000   1.000000  \n",
      "25%    1965.750000   1.000000  \n",
      "50%    1971.000000   2.000000  \n",
      "75%    1991.250000   7.000000  \n",
      "max    2011.000000  32.000000  \n",
      "\n",
      "[8 rows x 140 columns]\n",
      "****************************************************************************************************\n",
      "\n",
      "Train Data Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Columns: 184 entries, uid to j11_12\n",
      "dtypes: float64(140), object(44)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "          n_mar_03  migration_03  adl_dress_03  adl_walk_03  adl_bath_03  \\\n",
      "count  2222.000000   2241.000000   2105.000000  2235.000000  2235.000000   \n",
      "mean      1.134113      0.099063      0.041805     0.017002     0.007159   \n",
      "std       0.482953      0.298813      0.200191     0.129308     0.084325   \n",
      "min       0.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "25%       1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "50%       1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "75%       1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "max       5.000000      1.000000      1.000000     1.000000     1.000000   \n",
      "\n",
      "        adl_eat_03   adl_bed_03  adl_toilet_03     n_adl_03  iadl_money_03  \\\n",
      "count  2234.000000  2235.000000    2235.000000  2234.000000    2105.000000   \n",
      "mean      0.004476     0.026398       0.013423     0.068487       0.005226   \n",
      "std       0.066770     0.160352       0.115102     0.392793       0.072117   \n",
      "min       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "50%       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "75%       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "max       1.000000     1.000000       1.000000     5.000000       1.000000   \n",
      "\n",
      "       ...  searnings_12    hincome_12  hinc_business_12  hinc_rent_12  \\\n",
      "count  ...  2.091000e+03  3.138000e+03      3.187000e+03  3.187000e+03   \n",
      "mean   ...  1.181253e+04  8.824729e+04      3.294321e+04  8.628805e+02   \n",
      "std    ...  6.013394e+04  6.901728e+05      6.520799e+05  3.282440e+04   \n",
      "min    ...  0.000000e+00 -1.900000e+05      0.000000e+00 -3.600000e+05   \n",
      "25%    ...  0.000000e+00  0.000000e+00      0.000000e+00  0.000000e+00   \n",
      "50%    ...  0.000000e+00  2.000000e+04      0.000000e+00  0.000000e+00   \n",
      "75%    ...  0.000000e+00  6.000000e+04      0.000000e+00  0.000000e+00   \n",
      "max    ...  1.370000e+06  3.602000e+07      3.600000e+07  1.200000e+06   \n",
      "\n",
      "       hinc_assets_12   hinc_cap_12  rinc_pension_12  sinc_pension_12  \\\n",
      "count     3187.000000  3.187000e+03      3187.000000     2.091000e+03   \n",
      "mean       788.202071  3.458739e+04     13850.015689     1.193687e+04   \n",
      "std      10314.879890  6.527276e+05     44336.711380     4.705314e+04   \n",
      "min          0.000000 -2.100000e+05         0.000000     0.000000e+00   \n",
      "25%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "50%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "75%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "max     360000.000000  3.600000e+07    960000.000000     1.200000e+06   \n",
      "\n",
      "           a16a_12     a21_12  \n",
      "count    24.000000  42.000000  \n",
      "mean   1975.166667   7.833333  \n",
      "std      20.440086  12.585157  \n",
      "min    1942.000000   1.000000  \n",
      "25%    1960.000000   1.000000  \n",
      "50%    1972.500000   2.000000  \n",
      "75%    1988.500000   6.750000  \n",
      "max    2012.000000  52.000000  \n",
      "\n",
      "[8 rows x 140 columns]\n",
      "****************************************************************************************************\n",
      "\n",
      "Train Labels Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4343 entries, 0 to 4342\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   uid              4343 non-null   object\n",
      " 1   year             4343 non-null   int64 \n",
      " 2   composite_score  4343 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 101.9+ KB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "              year  composite_score\n",
      "count  4343.000000      4343.000000\n",
      "mean   2019.162560       157.016809\n",
      "std       2.410882        60.909546\n",
      "min    2016.000000         4.000000\n",
      "25%    2016.000000       114.000000\n",
      "50%    2021.000000       157.000000\n",
      "75%    2021.000000       200.000000\n",
      "max    2021.000000       334.000000\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "datasets = [(\"Test Data\", test_data), (\"Train Data\", train_data), (\"Train Labels\", train_labels)]\n",
    "for name, data in datas:\n",
    "    print(f\"\\n{name} Summary:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(data.describe())\n",
    "    print(\"*\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Data Overview ---\n",
      "Shape: (819, 184)\n",
      "Data Types:\n",
      "uid            object\n",
      "age_03         object\n",
      "urban_03       object\n",
      "married_03     object\n",
      "n_mar_03      float64\n",
      "               ...   \n",
      "a21_12        float64\n",
      "a22_12         object\n",
      "a33b_12        object\n",
      "a34_12         object\n",
      "j11_12         object\n",
      "Length: 184, dtype: object\n",
      "Null Values:\n",
      "uid             0\n",
      "age_03        249\n",
      "urban_03      249\n",
      "married_03    249\n",
      "n_mar_03      251\n",
      "             ... \n",
      "a21_12        808\n",
      "a22_12        809\n",
      "a33b_12       808\n",
      "a34_12        277\n",
      "j11_12         24\n",
      "Length: 184, dtype: int64\n",
      "Unique Values:\n",
      "uid           819\n",
      "age_03          5\n",
      "urban_03        2\n",
      "married_03      4\n",
      "n_mar_03        5\n",
      "             ... \n",
      "a21_12          5\n",
      "a22_12          4\n",
      "a33b_12         2\n",
      "a34_12          2\n",
      "j11_12          3\n",
      "Length: 184, dtype: int64\n",
      "*********************************************************************\n",
      "\n",
      "--- Train Data Overview ---\n",
      "Shape: (3276, 184)\n",
      "Data Types:\n",
      "uid            object\n",
      "age_03         object\n",
      "urban_03       object\n",
      "married_03     object\n",
      "n_mar_03      float64\n",
      "               ...   \n",
      "a21_12        float64\n",
      "a22_12         object\n",
      "a33b_12        object\n",
      "a34_12         object\n",
      "j11_12         object\n",
      "Length: 184, dtype: object\n",
      "Null Values:\n",
      "uid              0\n",
      "age_03        1036\n",
      "urban_03      1034\n",
      "married_03    1034\n",
      "n_mar_03      1054\n",
      "              ... \n",
      "a21_12        3234\n",
      "a22_12        3240\n",
      "a33b_12       3234\n",
      "a34_12        1164\n",
      "j11_12          75\n",
      "Length: 184, dtype: int64\n",
      "Unique Values:\n",
      "uid           3276\n",
      "age_03           5\n",
      "urban_03         2\n",
      "married_03       4\n",
      "n_mar_03         6\n",
      "              ... \n",
      "a21_12          15\n",
      "a22_12           7\n",
      "a33b_12          3\n",
      "a34_12           2\n",
      "j11_12           3\n",
      "Length: 184, dtype: int64\n",
      "*********************************************************************\n",
      "\n",
      "--- Train Labels Overview ---\n",
      "Shape: (4343, 3)\n",
      "Data Types:\n",
      "uid                object\n",
      "year                int64\n",
      "composite_score     int64\n",
      "dtype: object\n",
      "Null Values:\n",
      "uid                0\n",
      "year               0\n",
      "composite_score    0\n",
      "dtype: int64\n",
      "Unique Values:\n",
      "uid                3276\n",
      "year                  2\n",
      "composite_score     307\n",
      "dtype: int64\n",
      "*********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Checking dataset dimensions and data types\n",
    "for name, data in datasets:\n",
    "    print(f\"\\n--- {name} Overview ---\")\n",
    "    print(\"Shape:\", data.shape)\n",
    "    print(\"Data Types:\")\n",
    "    print(data.dtypes)\n",
    "    print(\"Null Values:\")\n",
    "    print(data.isnull().sum())\n",
    "    print(\"Unique Values:\")\n",
    "    print(data.nunique())\n",
    "    print('*********************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and percentage of missing values in each column\n",
    "missing_values_count = train_data.isnull().sum()\n",
    "missing_percentage = (missing_values_count / len(train_data)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid              0\n",
       "age_03        1036\n",
       "urban_03      1034\n",
       "married_03    1034\n",
       "n_mar_03      1054\n",
       "              ... \n",
       "a21_12        3234\n",
       "a22_12        3240\n",
       "a33b_12       3234\n",
       "a34_12        1164\n",
       "j11_12          75\n",
       "Length: 184, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid            0.000000\n",
       "age_03        31.623932\n",
       "urban_03      31.562882\n",
       "married_03    31.562882\n",
       "n_mar_03      32.173382\n",
       "                ...    \n",
       "a21_12        98.717949\n",
       "a22_12        98.901099\n",
       "a33b_12       98.717949\n",
       "a34_12        35.531136\n",
       "j11_12         2.289377\n",
       "Length: 184, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Missing Values  Percentage\n",
      "age_03                1036   31.623932\n",
      "urban_03              1034   31.562882\n",
      "married_03            1034   31.562882\n",
      "n_mar_03              1054   32.173382\n",
      "edu_gru_03            1044   31.868132\n",
      "...                    ...         ...\n",
      "a21_12                3234   98.717949\n",
      "a22_12                3240   98.901099\n",
      "a33b_12               3234   98.717949\n",
      "a34_12                1164   35.531136\n",
      "j11_12                  75    2.289377\n",
      "\n",
      "[182 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display missing values and their percentages\n",
    "missing_data = pd.DataFrame({\n",
    "    'Missing Values': missing_values_count,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "print(missing_data[missing_data['Missing Values'] > 0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying columns to drop (those with more than 40% missing values)\n",
    "columns_to_drop = missing_data[missing_data['Percentage'] > 40].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cleaned = train_data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Dropped:\n",
      "['bmi_03', 'decis_famil_03', 'sgender_03', 'rjob_hrswk_03', 'rjlocc_m_03', 'rjob_end_03', 'rjobend_reason_03', 'searnings_03', 'sinc_pension_03', 'rjob_hrswk_12', 'rjlocc_m_12', 'rjob_end_12', 'rjobend_reason_12', 'a16a_12', 'a21_12', 'a22_12', 'a33b_12']\n",
      "\n",
      "Cleaned DataFrame:\n",
      "    uid    age_03     urban_03  married_03  n_mar_03    edu_gru_03  \\\n",
      "0  aace       NaN          NaN         NaN       NaN           NaN   \n",
      "1  aanz       NaN          NaN         NaN       NaN           NaN   \n",
      "2  aape       NaN          NaN         NaN       NaN           NaN   \n",
      "3  aard  1. 50–59  1. 100,000+  3. Widowed       1.0  3. 7–9 years   \n",
      "4  ablr       NaN          NaN         NaN       NaN           NaN   \n",
      "\n",
      "  n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  ...  \\\n",
      "0               NaN           NaN          NaN           NaN  ...   \n",
      "1               NaN           NaN          NaN           NaN  ...   \n",
      "2               NaN           NaN          NaN           NaN  ...   \n",
      "3         1. 1 or 2           0.0      4. Fair           0.0  ...   \n",
      "4               NaN           NaN          NaN           NaN  ...   \n",
      "\n",
      "   hinc_assets_12  hinc_cap_12  rinc_pension_12  sinc_pension_12  \\\n",
      "0             0.0      10000.0              0.0              0.0   \n",
      "1             0.0          0.0              0.0              0.0   \n",
      "2             0.0          0.0              0.0              0.0   \n",
      "3             0.0          0.0              0.0              NaN   \n",
      "4             0.0          0.0              0.0              0.0   \n",
      "\n",
      "            rrelgimp_12            rrfcntx_m_12              rsocact_m_12  \\\n",
      "0  2.somewhat important                 9.Never                   9.Never   \n",
      "1      1.very important                 9.Never        1.Almost every day   \n",
      "2  2.somewhat important  6.2 or 3 times a month  2.4 or more times a week   \n",
      "3      1.very important           4.Once a week                   9.Never   \n",
      "4      1.very important   3.2 or 3 times a week     3.2 or 3 times a week   \n",
      "\n",
      "   rrelgwk_12  a34_12                             j11_12  \n",
      "0        0.No     NaN                         Concrete 2  \n",
      "1        0.No     NaN                         Concrete 2  \n",
      "2        0.No     NaN  Wood, mosaic, or other covering 1  \n",
      "3       1.Yes    No 2                         Concrete 2  \n",
      "4        0.No     NaN  Wood, mosaic, or other covering 1  \n",
      "\n",
      "[5 rows x 167 columns]\n"
     ]
    }
   ],
   "source": [
    "# Displaying the cleaned DataFrame and the columns dropped\n",
    "print(\"Columns Dropped:\")\n",
    "print(columns_to_drop.tolist())\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(train_data_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid', 'age_03', 'urban_03', 'married_03', 'n_mar_03', 'edu_gru_03', 'n_living_child_03', 'migration_03', 'glob_hlth_03', 'adl_dress_03', 'adl_walk_03', 'adl_bath_03', 'adl_eat_03', 'adl_bed_03', 'adl_toilet_03', 'n_adl_03', 'iadl_money_03', 'iadl_meds_03', 'iadl_shop_03', 'iadl_meals_03', 'n_iadl_03', 'depressed_03', 'hard_03', 'restless_03', 'happy_03', 'lonely_03', 'enjoy_03', 'sad_03', 'tired_03', 'energetic_03', 'n_depr_03', 'cesd_depressed_03', 'hypertension_03', 'diabetes_03', 'resp_ill_03', 'arthritis_03', 'hrt_attack_03', 'stroke_03', 'cancer_03', 'n_illnesses_03', 'exer_3xwk_03', 'alcohol_03', 'tobacco_03', 'test_chol_03', 'test_tuber_03', 'test_diab_03', 'test_pres_03', 'hosp_03', 'visit_med_03', 'out_proc_03', 'visit_dental_03', 'imss_03', 'issste_03', 'pem_def_mar_03', 'insur_private_03', 'insur_other_03', 'insured_03', 'decis_personal_03', 'employment_03', 'age_12', 'urban_12', 'married_12', 'n_mar_12', 'edu_gru_12', 'n_living_child_12', 'migration_12', 'glob_hlth_12', 'adl_dress_12', 'adl_walk_12', 'adl_bath_12', 'adl_eat_12', 'adl_bed_12', 'adl_toilet_12', 'n_adl_12', 'iadl_money_12', 'iadl_meds_12', 'iadl_shop_12', 'iadl_meals_12', 'n_iadl_12', 'depressed_12', 'hard_12', 'restless_12', 'happy_12', 'lonely_12', 'enjoy_12', 'sad_12', 'tired_12', 'energetic_12', 'n_depr_12', 'cesd_depressed_12', 'hypertension_12', 'diabetes_12', 'resp_ill_12', 'arthritis_12', 'hrt_attack_12', 'stroke_12', 'cancer_12', 'n_illnesses_12', 'bmi_12', 'exer_3xwk_12', 'alcohol_12', 'tobacco_12', 'test_chol_12', 'test_tuber_12', 'test_diab_12', 'test_pres_12', 'hosp_12', 'visit_med_12', 'out_proc_12', 'visit_dental_12', 'imss_12', 'issste_12', 'pem_def_mar_12', 'insur_private_12', 'insur_other_12', 'insured_12', 'decis_famil_12', 'decis_personal_12', 'employment_12', 'vax_flu_12', 'vax_pneu_12', 'seg_pop_12', 'care_adult_12', 'care_child_12', 'volunteer_12', 'attends_class_12', 'attends_club_12', 'reads_12', 'games_12', 'table_games_12', 'comms_tel_comp_12', 'act_mant_12', 'tv_12', 'sewing_12', 'satis_ideal_12', 'satis_excel_12', 'satis_fine_12', 'cosas_imp_12', 'wouldnt_change_12', 'memory_12', 'ragender', 'rameduc_m', 'rafeduc_m', 'rearnings_03', 'hincome_03', 'hinc_business_03', 'hinc_rent_03', 'hinc_assets_03', 'hinc_cap_03', 'rinc_pension_03', 'rrelgimp_03', 'sgender_12', 'rearnings_12', 'searnings_12', 'hincome_12', 'hinc_business_12', 'hinc_rent_12', 'hinc_assets_12', 'hinc_cap_12', 'rinc_pension_12', 'sinc_pension_12', 'rrelgimp_12', 'rrfcntx_m_12', 'rsocact_m_12', 'rrelgwk_12', 'a34_12', 'j11_12']\n"
     ]
    }
   ],
   "source": [
    "# Print all column names as a list\n",
    "print(list(train_data_cleaned.columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the features based on their types\n",
    "numerical_features = [\n",
    "    'age_03', 'age_12', 'rearnings_03', 'hincome_03', 'hinc_business_03', \n",
    "    'hinc_rent_03', 'hinc_assets_03', 'hinc_cap_03', 'rinc_pension_03',\n",
    "    'rearnings_12', 'searnings_12', 'hincome_12', 'hinc_business_12', \n",
    "    'hinc_rent_12', 'hinc_assets_12', 'hinc_cap_12', 'rinc_pension_12', \n",
    "    'sinc_pension_12', 'n_mar_03', 'n_living_child_03', 'n_mar_12', \n",
    "    'n_living_child_12', 'glob_hlth_03', 'glob_hlth_12', 'bmi_12',\n",
    "    'visit_med_03', 'visit_med_12', 'test_chol_03', 'test_chol_12',\n",
    "    'test_tuber_03', 'test_tuber_12', 'test_diab_03', 'test_diab_12', \n",
    "    'test_pres_03', 'test_pres_12'\n",
    "]\n",
    "\n",
    "ordinal_features = [\n",
    "    'glob_hlth_03', 'adl_dress_03', 'adl_walk_03', 'adl_bath_03', \n",
    "    'adl_eat_03', 'adl_bed_03', 'adl_toilet_03', 'n_adl_03', 'iadl_money_03', \n",
    "    'iadl_meds_03', 'iadl_shop_03', 'iadl_meals_03', 'n_iadl_03', \n",
    "    'n_depr_03', 'depressed_03', 'happy_03', 'lonely_03', 'enjoy_03', \n",
    "    'sad_03', 'tired_03', 'energetic_03', 'cesd_depressed_03',\n",
    "    'glob_hlth_12', 'adl_dress_12', 'adl_walk_12', 'adl_bath_12', \n",
    "    'adl_eat_12', 'adl_bed_12', 'adl_toilet_12', 'n_adl_12', 'iadl_money_12', \n",
    "    'iadl_meds_12', 'iadl_shop_12', 'iadl_meals_12', 'n_iadl_12', \n",
    "    'n_depr_12', 'depressed_12', 'happy_12', 'lonely_12', 'enjoy_12', \n",
    "    'sad_12', 'tired_12', 'energetic_12', 'cesd_depressed_12'\n",
    "]\n",
    "\n",
    "nominal_features = [\n",
    "    'hypertension_03', 'diabetes_03', 'arthritis_03', 'hrt_attack_03', \n",
    "    'stroke_03', 'cancer_03', 'exer_3xwk_03', 'alcohol_03', 'tobacco_03', \n",
    "    'hosp_03', 'imss_03', 'issste_03', 'insur_private_03', 'insur_other_03', \n",
    "    'insured_03', 'employment_03', 'hypertension_12', 'diabetes_12', \n",
    "    'arthritis_12', 'hrt_attack_12', 'stroke_12', 'cancer_12', 'exer_3xwk_12', \n",
    "    'alcohol_12', 'tobacco_12', 'hosp_12', 'imss_12', 'issste_12', \n",
    "    'insur_private_12', 'insur_other_12', 'insured_12', 'employment_12', \n",
    "    'volunteer_12', 'attends_class_12', 'attends_club_12', 'reads_12', \n",
    "    'games_12', 'tv_12'\n",
    "]\n",
    "\n",
    "demographic_features = [\n",
    "    'ragender', 'sgender_12', 'rameduc_m', 'rafeduc_m', 'rrelgimp_03', 'rrelgimp_12'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle missing values based on feature groups\n",
    "def handle_missing_values(train_data_cleaned):\n",
    "    # Numerical Features: Mean/Median Imputation (only for numeric columns)\n",
    "    for col in numerical_features:\n",
    "        if pd.api.types.is_numeric_dtype(train_data_cleaned[col]):\n",
    "            train_data_cleaned[col].fillna(train_data_cleaned[col].mean(), inplace=True)\n",
    "    \n",
    "    # Ordinal Features: Mode Imputation\n",
    "    for col in ordinal_features:\n",
    "        train_data_cleaned[col].fillna(train_data_cleaned[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Nominal Features: Mode Imputation\n",
    "    for col in nominal_features:\n",
    "        train_data_cleaned[col].fillna(train_data_cleaned[col].mode()[0], inplace=True)\n",
    "    \n",
    "    # Demographic Features: Mode Imputation\n",
    "    for col in demographic_features:\n",
    "        train_data_cleaned[col].fillna(train_data_cleaned[col].mode()[0], inplace=True)\n",
    "    \n",
    "    return train_data_cleaned\n",
    "\n",
    "# Apply the function to clean the dataframe\n",
    "train_data_cleaned = handle_missing_values(train_data_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>...</th>\n",
       "      <th>hinc_assets_12</th>\n",
       "      <th>hinc_cap_12</th>\n",
       "      <th>rinc_pension_12</th>\n",
       "      <th>sinc_pension_12</th>\n",
       "      <th>rrelgimp_12</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aanz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Almost every day</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.somewhat important</td>\n",
       "      <td>6.2 or 3 times a month</td>\n",
       "      <td>2.4 or more times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aard</td>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>3. Widowed</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3. 7–9 years</td>\n",
       "      <td>1. 1 or 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11936.87231</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>4.Once a week</td>\n",
       "      <td>9.Never</td>\n",
       "      <td>1.Yes</td>\n",
       "      <td>No 2</td>\n",
       "      <td>Concrete 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4. Fair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.very important</td>\n",
       "      <td>3.2 or 3 times a week</td>\n",
       "      <td>3.2 or 3 times a week</td>\n",
       "      <td>0.No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood, mosaic, or other covering 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid    age_03     urban_03  married_03  n_mar_03    edu_gru_03  \\\n",
       "0  aace       NaN          NaN         NaN  1.134113           NaN   \n",
       "1  aanz       NaN          NaN         NaN  1.134113           NaN   \n",
       "2  aape       NaN          NaN         NaN  1.134113           NaN   \n",
       "3  aard  1. 50–59  1. 100,000+  3. Widowed  1.000000  3. 7–9 years   \n",
       "4  ablr       NaN          NaN         NaN  1.134113           NaN   \n",
       "\n",
       "  n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  ...  \\\n",
       "0               NaN           NaN      4. Fair           0.0  ...   \n",
       "1               NaN           NaN      4. Fair           0.0  ...   \n",
       "2               NaN           NaN      4. Fair           0.0  ...   \n",
       "3         1. 1 or 2           0.0      4. Fair           0.0  ...   \n",
       "4               NaN           NaN      4. Fair           0.0  ...   \n",
       "\n",
       "   hinc_assets_12  hinc_cap_12  rinc_pension_12  sinc_pension_12  \\\n",
       "0             0.0      10000.0              0.0          0.00000   \n",
       "1             0.0          0.0              0.0          0.00000   \n",
       "2             0.0          0.0              0.0          0.00000   \n",
       "3             0.0          0.0              0.0      11936.87231   \n",
       "4             0.0          0.0              0.0          0.00000   \n",
       "\n",
       "            rrelgimp_12            rrfcntx_m_12              rsocact_m_12  \\\n",
       "0  2.somewhat important                 9.Never                   9.Never   \n",
       "1      1.very important                 9.Never        1.Almost every day   \n",
       "2  2.somewhat important  6.2 or 3 times a month  2.4 or more times a week   \n",
       "3      1.very important           4.Once a week                   9.Never   \n",
       "4      1.very important   3.2 or 3 times a week     3.2 or 3 times a week   \n",
       "\n",
       "   rrelgwk_12  a34_12                             j11_12  \n",
       "0        0.No     NaN                         Concrete 2  \n",
       "1        0.No     NaN                         Concrete 2  \n",
       "2        0.No     NaN  Wood, mosaic, or other covering 1  \n",
       "3       1.Yes    No 2                         Concrete 2  \n",
       "4        0.No     NaN  Wood, mosaic, or other covering 1  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate numeric part from string-encoded categorical values\n",
    "def clean_encoded_strings(train_data_cleaned, columns):\n",
    "    for col in columns:\n",
    "        if col in train_data_cleaned.columns:  # Check if column exists\n",
    "            # Extract numeric part only (if it exists)\n",
    "            train_data_cleaned[col] = train_data_cleaned[col].astype(str).fillna('').str.extract('(\\d+)').astype(float)\n",
    "    return train_data_cleaned\n",
    "\n",
    "# List of columns that need cleaning for encoded values\n",
    "encoded_columns = [\n",
    "    'married_03', 'edu_gru_03', 'n_living_child_03', 'glob_hlth_03', 'bmi_03', 'decis_famil_03', \n",
    "    'employment_03', 'age_12', 'urban_12', 'married_12', 'edu_gru_12', 'n_living_child_12', \n",
    "    'glob_hlth_12', 'bmi_12', 'decis_famil_12', 'decis_personal_12', 'employment_12', \n",
    "    'satis_ideal_12', 'satis_excel_12', 'satis_fine_12', 'cosas_imp_12', 'wouldnt_change_12', \n",
    "    'memory_12', 'ragender', 'rameduc_m', 'rafeduc_m', 'sgender_03', 'rjlocc_m_03', \n",
    "    'rjobend_reason_03', 'rrelgimp_03', 'sgender_12', 'rjlocc_m_12', 'rjobend_reason_12', \n",
    "    'rrelgimp_12', 'rrfcntx_m_12', 'rsocact_m_12', 'rrelgwk_12', 'a34_12', 'j11_12'\n",
    "]\n",
    "\n",
    "# Clean the encoded columns\n",
    "train_data_cleaned = clean_encoded_strings(train_data_cleaned, encoded_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3276, 167)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>age_03</th>\n",
       "      <th>urban_03</th>\n",
       "      <th>married_03</th>\n",
       "      <th>n_mar_03</th>\n",
       "      <th>edu_gru_03</th>\n",
       "      <th>n_living_child_03</th>\n",
       "      <th>migration_03</th>\n",
       "      <th>glob_hlth_03</th>\n",
       "      <th>adl_dress_03</th>\n",
       "      <th>...</th>\n",
       "      <th>hinc_assets_12</th>\n",
       "      <th>hinc_cap_12</th>\n",
       "      <th>rinc_pension_12</th>\n",
       "      <th>sinc_pension_12</th>\n",
       "      <th>rrelgimp_12</th>\n",
       "      <th>rrfcntx_m_12</th>\n",
       "      <th>rsocact_m_12</th>\n",
       "      <th>rrelgwk_12</th>\n",
       "      <th>a34_12</th>\n",
       "      <th>j11_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aanz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aape</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aard</td>\n",
       "      <td>1. 50–59</td>\n",
       "      <td>1. 100,000+</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11936.87231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid    age_03     urban_03  married_03  n_mar_03  edu_gru_03  \\\n",
       "0  aace       NaN          NaN         NaN  1.134113         NaN   \n",
       "1  aanz       NaN          NaN         NaN  1.134113         NaN   \n",
       "2  aape       NaN          NaN         NaN  1.134113         NaN   \n",
       "3  aard  1. 50–59  1. 100,000+         3.0  1.000000         3.0   \n",
       "4  ablr       NaN          NaN         NaN  1.134113         NaN   \n",
       "\n",
       "   n_living_child_03  migration_03  glob_hlth_03  adl_dress_03  ...  \\\n",
       "0                NaN           NaN           4.0           0.0  ...   \n",
       "1                NaN           NaN           4.0           0.0  ...   \n",
       "2                NaN           NaN           4.0           0.0  ...   \n",
       "3                1.0           0.0           4.0           0.0  ...   \n",
       "4                NaN           NaN           4.0           0.0  ...   \n",
       "\n",
       "   hinc_assets_12  hinc_cap_12  rinc_pension_12  sinc_pension_12  rrelgimp_12  \\\n",
       "0             0.0      10000.0              0.0          0.00000          2.0   \n",
       "1             0.0          0.0              0.0          0.00000          1.0   \n",
       "2             0.0          0.0              0.0          0.00000          2.0   \n",
       "3             0.0          0.0              0.0      11936.87231          1.0   \n",
       "4             0.0          0.0              0.0          0.00000          1.0   \n",
       "\n",
       "   rrfcntx_m_12  rsocact_m_12  rrelgwk_12  a34_12  j11_12  \n",
       "0           9.0           9.0         0.0     NaN     2.0  \n",
       "1           9.0           1.0         0.0     NaN     2.0  \n",
       "2           6.0           2.0         0.0     NaN     1.0  \n",
       "3           4.0           9.0         1.0     2.0     2.0  \n",
       "4           3.0           3.0         0.0     NaN     1.0  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column Name  Missing Count\n",
      "116     decis_famil_12           1226\n",
      "57   decis_personal_03           1178\n",
      "23         restless_03           1172\n",
      "22             hard_03           1172\n",
      "165             a34_12           1164\n",
      "6    n_living_child_03           1046\n",
      "5           edu_gru_03           1044\n",
      "1               age_03           1036\n",
      "7         migration_03           1035\n",
      "39      n_illnesses_03           1035\n",
      "34         resp_ill_03           1034\n",
      "3           married_03           1034\n",
      "2             urban_03           1034\n",
      "53      pem_def_mar_03           1034\n",
      "50     visit_dental_03           1034\n",
      "49         out_proc_03           1034\n",
      "98              bmi_12            438\n",
      "120        vax_pneu_12            291\n",
      "134     satis_ideal_12            277\n",
      "138  wouldnt_change_12            248\n",
      "139          memory_12            245\n",
      "135     satis_excel_12            239\n",
      "137       cosas_imp_12            228\n",
      "162       rrfcntx_m_12            225\n",
      "117  decis_personal_12            225\n",
      "119         vax_flu_12            223\n",
      "136      satis_fine_12            223\n",
      "129     table_games_12            219\n",
      "81         restless_12            219\n",
      "80             hard_12            218\n",
      "130  comms_tel_comp_12            218\n",
      "164         rrelgwk_12            218\n",
      "123      care_child_12            217\n",
      "122      care_adult_12            216\n",
      "131        act_mant_12            216\n",
      "133          sewing_12            216\n",
      "163       rsocact_m_12            216\n",
      "97      n_illnesses_12            118\n",
      "64   n_living_child_12            110\n",
      "63          edu_gru_12            100\n",
      "109    visit_dental_12             95\n",
      "92         resp_ill_12             94\n",
      "108        out_proc_12             90\n",
      "59              age_12             90\n",
      "121         seg_pop_12             89\n",
      "112     pem_def_mar_12             89\n",
      "65        migration_12             89\n",
      "61          married_12             89\n",
      "60            urban_12             89\n",
      "166             j11_12             75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "missing_values = train_data_cleaned.isnull().sum()\n",
    "\n",
    "\n",
    "missing_values_df = pd.DataFrame(missing_values, columns=['Missing Count']).reset_index()\n",
    "missing_values_df.columns = ['Column Name', 'Missing Count']\n",
    "\n",
    "\n",
    "non_zero_missing_df = missing_values_df[missing_values_df['Missing Count'] > 0]\n",
    "\n",
    "\n",
    "non_zero_missing_df = non_zero_missing_df.sort_values(by='Missing Count', ascending=False)\n",
    "\n",
    "\n",
    "print(non_zero_missing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Categorical Columns: Fill missing values with the mode (most frequent value)\n",
    "# Explanation: For categorical data, the most frequent value often makes a reasonable assumption for the missing value.\n",
    "categorical_columns = [\n",
    "    'age_03', 'edu_gru_03', 'married_03', 'urban_03'\n",
    "]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    # Check if mode exists and handle the case where mode is empty\n",
    "    mode_value = train_data_cleaned[col].mode()\n",
    "    if not mode_value.empty:\n",
    "        train_data_cleaned[col].fillna(mode_value[0], inplace=True)\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} has no mode (empty column).\")\n",
    "\n",
    "# 2. Binary Columns: Fill missing values with the most frequent value in the column\n",
    "# Explanation: Since binary columns typically have two values, using the most common (e.g., 0 or 1) aligns with the prevailing trend.\n",
    "binary_columns = [\n",
    "    'migration_03', 'pem_def_mar_03', 'resp_ill_03', 'hard_03'\n",
    "]\n",
    "\n",
    "for col in binary_columns:\n",
    "    most_frequent = train_data_cleaned[col].value_counts().idxmax() if not train_data_cleaned[col].value_counts().empty else None\n",
    "    if most_frequent is not None:\n",
    "        train_data_cleaned[col].fillna(most_frequent, inplace=True)\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} has no values to determine most frequent.\")\n",
    "\n",
    "# 3. Numerical Columns: Fill missing values with the median\n",
    "# Explanation: For numerical columns, the median is a robust measure, especially if the data is skewed.\n",
    "numerical_columns = [\n",
    "    'n_living_child_03', 'n_illnesses_03', 'vax_pneu_12'\n",
    "]\n",
    "\n",
    "for col in numerical_columns:\n",
    "    if train_data_cleaned[col].notna().sum() > 0:\n",
    "        train_data_cleaned[col].fillna(train_data_cleaned[col].median(), inplace=True)\n",
    "    else:\n",
    "        print(f\"Warning: Column {col} has no numeric values for median calculation.\")\n",
    "\n",
    "# 4. Year-Based Feature Engineering: Interpolate missing values between 2003 and 2012 for paired columns\n",
    "# Explanation: For columns where data is available across multiple years, filling missing values in one year\n",
    "# by referencing the other year’s value can provide a reasonable estimate, assuming stability over time.\n",
    "paired_columns = [\n",
    "    ('resp_ill_03', 'resp_ill_12')\n",
    "]\n",
    "\n",
    "for col_03, col_12 in paired_columns:\n",
    "    train_data_cleaned[col_03].fillna(train_data_cleaned[col_12], inplace=True)\n",
    "    train_data_cleaned[col_12].fillna(train_data_cleaned[col_03], inplace=True)\n",
    "\n",
    "# 5. New Feature Creation for Missing Indicators: Add binary columns to indicate missing data\n",
    "# Explanation: Adding binary \"missing\" indicators helps capture missingness as a feature, which can\n",
    "# contribute useful signals during analysis or modeling.\n",
    "missing_indicators = [\n",
    "    'depressed_03', 'decis_famil_12'\n",
    "]\n",
    "\n",
    "for col in missing_indicators:\n",
    "    train_data_cleaned[f'{col}_missing'] = train_data_cleaned[col].isnull().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid                          0\n",
       "age_03                       0\n",
       "urban_03                     0\n",
       "married_03                   0\n",
       "n_mar_03                     0\n",
       "                          ... \n",
       "rrelgwk_12                 218\n",
       "a34_12                    1164\n",
       "j11_12                      75\n",
       "depressed_03_missing         0\n",
       "decis_famil_12_missing       0\n",
       "Length: 169, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column Name  Missing Count\n",
      "116     decis_famil_12           1226\n",
      "57   decis_personal_03           1178\n",
      "23         restless_03           1172\n",
      "165             a34_12           1164\n",
      "50     visit_dental_03           1034\n",
      "49         out_proc_03           1034\n",
      "98              bmi_12            438\n",
      "134     satis_ideal_12            277\n",
      "138  wouldnt_change_12            248\n",
      "139          memory_12            245\n",
      "135     satis_excel_12            239\n",
      "137       cosas_imp_12            228\n",
      "162       rrfcntx_m_12            225\n",
      "117  decis_personal_12            225\n",
      "136      satis_fine_12            223\n",
      "119         vax_flu_12            223\n",
      "81         restless_12            219\n",
      "129     table_games_12            219\n",
      "164         rrelgwk_12            218\n",
      "80             hard_12            218\n",
      "130  comms_tel_comp_12            218\n",
      "123      care_child_12            217\n",
      "122      care_adult_12            216\n",
      "131        act_mant_12            216\n",
      "133          sewing_12            216\n",
      "163       rsocact_m_12            216\n",
      "97      n_illnesses_12            118\n",
      "64   n_living_child_12            110\n",
      "63          edu_gru_12            100\n",
      "109    visit_dental_12             95\n",
      "59              age_12             90\n",
      "108        out_proc_12             90\n",
      "60            urban_12             89\n",
      "112     pem_def_mar_12             89\n",
      "61          married_12             89\n",
      "65        migration_12             89\n",
      "121         seg_pop_12             89\n",
      "166             j11_12             75\n"
     ]
    }
   ],
   "source": [
    "missing_values_after = train_data_cleaned.isnull().sum()\n",
    "\n",
    "\n",
    "missing_values_after_df = pd.DataFrame(missing_values_after, columns=['Missing Count']).reset_index()\n",
    "missing_values_after_df.columns = ['Column Name', 'Missing Count']\n",
    "\n",
    "\n",
    "non_zero_missing_after_df = missing_values_after_df[missing_values_after_df['Missing Count'] > 0]\n",
    "\n",
    "\n",
    "non_zero_missing_after_df = non_zero_missing_after_df.sort_values(by='Missing Count', ascending=False)\n",
    "\n",
    "print(non_zero_missing_after_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicate_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
