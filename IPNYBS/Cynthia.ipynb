{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    uid    age_03     urban_03  married_03  n_mar_03    edu_gru_03  \\\n",
      "0  aace       NaN          NaN         NaN       NaN           NaN   \n",
      "1  aanz       NaN          NaN         NaN       NaN           NaN   \n",
      "2  aape       NaN          NaN         NaN       NaN           NaN   \n",
      "3  aard  1. 50–59  1. 100,000+  3. Widowed       1.0  3. 7–9 years   \n",
      "4  ablr       NaN          NaN         NaN       NaN           NaN   \n",
      "\n",
      "  n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  ...  \\\n",
      "0               NaN           NaN          NaN           NaN  ...   \n",
      "1               NaN           NaN          NaN           NaN  ...   \n",
      "2               NaN           NaN          NaN           NaN  ...   \n",
      "3         1. 1 or 2           0.0      4. Fair           0.0  ...   \n",
      "4               NaN           NaN          NaN           NaN  ...   \n",
      "\n",
      "            rrelgimp_12            rrfcntx_m_12              rsocact_m_12  \\\n",
      "0  2.somewhat important                 9.Never                   9.Never   \n",
      "1      1.very important                 9.Never        1.Almost every day   \n",
      "2  2.somewhat important  6.2 or 3 times a month  2.4 or more times a week   \n",
      "3      1.very important           4.Once a week                   9.Never   \n",
      "4      1.very important   3.2 or 3 times a week     3.2 or 3 times a week   \n",
      "\n",
      "   rrelgwk_12  a16a_12  a21_12  a22_12  a33b_12  a34_12  \\\n",
      "0        0.No      NaN     NaN     NaN      NaN     NaN   \n",
      "1        0.No      NaN     NaN     NaN      NaN     NaN   \n",
      "2        0.No      NaN     NaN     NaN      NaN     NaN   \n",
      "3       1.Yes      NaN     NaN     NaN      NaN    No 2   \n",
      "4        0.No      NaN     NaN     NaN      NaN     NaN   \n",
      "\n",
      "                              j11_12  \n",
      "0                         Concrete 2  \n",
      "1                         Concrete 2  \n",
      "2  Wood, mosaic, or other covering 1  \n",
      "3                         Concrete 2  \n",
      "4  Wood, mosaic, or other covering 1  \n",
      "\n",
      "[5 rows x 184 columns]\n",
      "    uid    age_03     urban_03                    married_03  n_mar_03  \\\n",
      "0  abxu       NaN          NaN                           NaN       NaN   \n",
      "1  aeol       NaN          NaN                           NaN       NaN   \n",
      "2  afnb       NaN          NaN                           NaN       NaN   \n",
      "3  ajfh       NaN          NaN                           NaN       NaN   \n",
      "4  ajvq  2. 60–69  1. 100,000+  1. Married or in civil union       1.0   \n",
      "\n",
      "     edu_gru_03 n_living_child_03  migration_03 glob_hlth_03  adl_dress_03  \\\n",
      "0           NaN               NaN           NaN          NaN           NaN   \n",
      "1           NaN               NaN           NaN          NaN           NaN   \n",
      "2           NaN               NaN           NaN          NaN           NaN   \n",
      "3           NaN               NaN           NaN          NaN           NaN   \n",
      "4  4. 10+ years         1. 1 or 2           0.0          NaN           NaN   \n",
      "\n",
      "   ...           rrelgimp_12        rrfcntx_m_12               rsocact_m_12  \\\n",
      "0  ...                   NaN                 NaN                        NaN   \n",
      "1  ...      1.very important             9.Never                    9.Never   \n",
      "2  ...      1.very important             9.Never      3.2 or 3 times a week   \n",
      "3  ...  2.somewhat important             9.Never  5.4 or more times a month   \n",
      "4  ...  2.somewhat important  1.Almost every day              4.Once a week   \n",
      "\n",
      "   rrelgwk_12  a16a_12  a21_12  a22_12  a33b_12  a34_12  \\\n",
      "0         NaN      NaN     NaN     NaN      NaN     NaN   \n",
      "1       1.Yes      NaN     NaN     NaN      NaN     NaN   \n",
      "2       1.Yes      NaN     NaN     NaN      NaN     NaN   \n",
      "3        0.No      NaN     NaN     NaN      NaN     NaN   \n",
      "4        0.No      NaN     NaN     NaN      NaN    No 2   \n",
      "\n",
      "                              j11_12  \n",
      "0  Wood, mosaic, or other covering 1  \n",
      "1                         Concrete 2  \n",
      "2  Wood, mosaic, or other covering 1  \n",
      "3  Wood, mosaic, or other covering 1  \n",
      "4  Wood, mosaic, or other covering 1  \n",
      "\n",
      "[5 rows x 184 columns]\n",
      "    uid  year  composite_score\n",
      "0  aace  2021              175\n",
      "1  aanz  2021              206\n",
      "2  aape  2016              161\n",
      "3  aape  2021              144\n",
      "4  aard  2021              104\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_features = pd.read_csv(r\"C:\\Users\\David\\Documents\\PHASE 4 PROJECT\\PHASE 5 FINAL PROJECT\\train_features.csv\")\n",
    "test_features = pd.read_csv(r\"C:\\Users\\David\\Documents\\PHASE 4 PROJECT\\PHASE 5 FINAL PROJECT\\test_features.csv\")\n",
    "train_labels = pd.read_csv(r\"C:\\Users\\David\\Documents\\PHASE 4 PROJECT\\PHASE 5 FINAL PROJECT\\train_labels.csv\")\n",
    "\n",
    "# Check the first few rows of each dataframe\n",
    "print(train_features.head())\n",
    "print(test_features.head())\n",
    "print(train_labels.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) View Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          n_mar_03  migration_03  adl_dress_03  adl_walk_03  adl_bath_03  \\\n",
      "count  2222.000000   2241.000000   2105.000000  2235.000000  2235.000000   \n",
      "mean      1.134113      0.099063      0.041805     0.017002     0.007159   \n",
      "std       0.482953      0.298813      0.200191     0.129308     0.084325   \n",
      "min       0.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "25%       1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "50%       1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "75%       1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "max       5.000000      1.000000      1.000000     1.000000     1.000000   \n",
      "\n",
      "        adl_eat_03   adl_bed_03  adl_toilet_03     n_adl_03  iadl_money_03  \\\n",
      "count  2234.000000  2235.000000    2235.000000  2234.000000    2105.000000   \n",
      "mean      0.004476     0.026398       0.013423     0.068487       0.005226   \n",
      "std       0.066770     0.160352       0.115102     0.392793       0.072117   \n",
      "min       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "50%       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "75%       0.000000     0.000000       0.000000     0.000000       0.000000   \n",
      "max       1.000000     1.000000       1.000000     5.000000       1.000000   \n",
      "\n",
      "       ...  searnings_12    hincome_12  hinc_business_12  hinc_rent_12  \\\n",
      "count  ...  2.091000e+03  3.138000e+03      3.187000e+03  3.187000e+03   \n",
      "mean   ...  1.181253e+04  8.824729e+04      3.294321e+04  8.628805e+02   \n",
      "std    ...  6.013394e+04  6.901728e+05      6.520799e+05  3.282440e+04   \n",
      "min    ...  0.000000e+00 -1.900000e+05      0.000000e+00 -3.600000e+05   \n",
      "25%    ...  0.000000e+00  0.000000e+00      0.000000e+00  0.000000e+00   \n",
      "50%    ...  0.000000e+00  2.000000e+04      0.000000e+00  0.000000e+00   \n",
      "75%    ...  0.000000e+00  6.000000e+04      0.000000e+00  0.000000e+00   \n",
      "max    ...  1.370000e+06  3.602000e+07      3.600000e+07  1.200000e+06   \n",
      "\n",
      "       hinc_assets_12   hinc_cap_12  rinc_pension_12  sinc_pension_12  \\\n",
      "count     3187.000000  3.187000e+03      3187.000000     2.091000e+03   \n",
      "mean       788.202071  3.458739e+04     13850.015689     1.193687e+04   \n",
      "std      10314.879890  6.527276e+05     44336.711380     4.705314e+04   \n",
      "min          0.000000 -2.100000e+05         0.000000     0.000000e+00   \n",
      "25%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "50%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "75%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "max     360000.000000  3.600000e+07    960000.000000     1.200000e+06   \n",
      "\n",
      "           a16a_12     a21_12  \n",
      "count    24.000000  42.000000  \n",
      "mean   1975.166667   7.833333  \n",
      "std      20.440086  12.585157  \n",
      "min    1942.000000   1.000000  \n",
      "25%    1960.000000   1.000000  \n",
      "50%    1972.500000   2.000000  \n",
      "75%    1988.500000   6.750000  \n",
      "max    2012.000000  52.000000  \n",
      "\n",
      "[8 rows x 140 columns]\n",
      "         n_mar_03  migration_03  adl_dress_03  adl_walk_03  adl_bath_03  \\\n",
      "count  568.000000    570.000000    542.000000   569.000000   569.000000   \n",
      "mean     1.165493      0.077193      0.047970     0.012302     0.012302   \n",
      "std      0.535254      0.267132      0.213901     0.110328     0.110328   \n",
      "min      0.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "25%      1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "50%      1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "75%      1.000000      0.000000      0.000000     0.000000     0.000000   \n",
      "max      4.000000      1.000000      1.000000     1.000000     1.000000   \n",
      "\n",
      "       adl_eat_03  adl_bed_03  adl_toilet_03    n_adl_03  iadl_money_03  ...  \\\n",
      "count  569.000000  569.000000     569.000000  569.000000     542.000000  ...   \n",
      "mean     0.005272    0.038664       0.019332    0.087873       0.009225  ...   \n",
      "std      0.072483    0.192963       0.137811    0.443272       0.095692  ...   \n",
      "min      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "25%      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "50%      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "75%      0.000000    0.000000       0.000000    0.000000       0.000000  ...   \n",
      "max      1.000000    1.000000       1.000000    5.000000       1.000000  ...   \n",
      "\n",
      "        searnings_12    hincome_12  hinc_business_12   hinc_rent_12  \\\n",
      "count     508.000000  7.730000e+02      7.940000e+02     794.000000   \n",
      "mean    10196.850394  6.608021e+04      1.010076e+04    2216.624685   \n",
      "std     35871.244519  2.540155e+05      7.190606e+04   35284.803065   \n",
      "min         0.000000 -2.000000e+05      0.000000e+00 -200000.000000   \n",
      "25%         0.000000  0.000000e+00      0.000000e+00       0.000000   \n",
      "50%         0.000000  2.000000e+04      0.000000e+00       0.000000   \n",
      "75%         0.000000  5.000000e+04      0.000000e+00       0.000000   \n",
      "max    310000.000000  6.020000e+06      1.430000e+06  710000.000000   \n",
      "\n",
      "       hinc_assets_12   hinc_cap_12  rinc_pension_12  sinc_pension_12  \\\n",
      "count      794.000000  7.940000e+02       794.000000     5.080000e+02   \n",
      "mean       367.758186  1.265743e+04     13476.070529     1.039370e+04   \n",
      "std       4482.643368  8.003225e+04     38708.762304     5.315530e+04   \n",
      "min          0.000000 -2.000000e+05         0.000000     0.000000e+00   \n",
      "25%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "50%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "75%          0.000000  0.000000e+00         0.000000     0.000000e+00   \n",
      "max      84000.000000  1.430000e+06    480000.000000     1.080000e+06   \n",
      "\n",
      "           a16a_12     a21_12  \n",
      "count     6.000000  11.000000  \n",
      "mean   1975.833333   6.454545  \n",
      "std      25.103121   9.771015  \n",
      "min    1940.000000   1.000000  \n",
      "25%    1965.750000   1.000000  \n",
      "50%    1971.000000   2.000000  \n",
      "75%    1991.250000   7.000000  \n",
      "max    2011.000000  32.000000  \n",
      "\n",
      "[8 rows x 140 columns]\n",
      "              year  composite_score\n",
      "count  4343.000000      4343.000000\n",
      "mean   2019.162560       157.016809\n",
      "std       2.410882        60.909546\n",
      "min    2016.000000         4.000000\n",
      "25%    2016.000000       114.000000\n",
      "50%    2021.000000       157.000000\n",
      "75%    2021.000000       200.000000\n",
      "max    2021.000000       334.000000\n"
     ]
    }
   ],
   "source": [
    "print(train_features.describe())\n",
    "print(test_features.describe())\n",
    "print(train_labels.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Checking and Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid              0\n",
      "age_03        1036\n",
      "urban_03      1034\n",
      "married_03    1034\n",
      "n_mar_03      1054\n",
      "              ... \n",
      "a21_12        3234\n",
      "a22_12        3240\n",
      "a33b_12       3234\n",
      "a34_12        1164\n",
      "j11_12          75\n",
      "Length: 184, dtype: int64\n",
      "uid             0\n",
      "age_03        249\n",
      "urban_03      249\n",
      "married_03    249\n",
      "n_mar_03      251\n",
      "             ... \n",
      "a21_12        808\n",
      "a22_12        809\n",
      "a33b_12       808\n",
      "a34_12        277\n",
      "j11_12         24\n",
      "Length: 184, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find missing values\n",
    "print(train_features.isnull().sum())\n",
    "print(test_features.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are so many missing values in this dataset. I will proceed with handling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 40% missing values in both datasets\n",
    "threshold = 0.4\n",
    "train_features_cleaned = train_features.loc[:, train_features.isnull().mean() < threshold]\n",
    "test_features_cleaned = test_features.loc[:, test_features.isnull().mean() < threshold]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values for numerical features\n",
    "for col in train_features_cleaned.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    train_features_cleaned[col].fillna(train_features_cleaned[col].mean(), inplace=True)\n",
    "\n",
    "for col in test_features_cleaned.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    test_features_cleaned[col].fillna(test_features_cleaned[col].mean(), inplace=True)\n",
    "\n",
    "# Impute missing values for categorical features\n",
    "for col in train_features_cleaned.select_dtypes(include=['object']).columns:\n",
    "    train_features_cleaned[col].fillna(train_features_cleaned[col].mode()[0], inplace=True)\n",
    "\n",
    "for col in test_features_cleaned.select_dtypes(include=['object']).columns:\n",
    "    test_features_cleaned[col].fillna(test_features_cleaned[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid            object\n",
      "age_03         object\n",
      "urban_03       object\n",
      "married_03     object\n",
      "n_mar_03      float64\n",
      "               ...   \n",
      "a21_12        float64\n",
      "a22_12         object\n",
      "a33b_12        object\n",
      "a34_12         object\n",
      "j11_12         object\n",
      "Length: 184, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_features.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Columns for Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Columns:\n",
      " Index(['uid', 'age_03', 'urban_03', 'married_03', 'edu_gru_03',\n",
      "       'n_living_child_03', 'glob_hlth_03', 'bmi_03', 'decis_famil_03',\n",
      "       'employment_03', 'age_12', 'urban_12', 'married_12', 'edu_gru_12',\n",
      "       'n_living_child_12', 'glob_hlth_12', 'bmi_12', 'decis_famil_12',\n",
      "       'decis_personal_12', 'employment_12', 'satis_ideal_12',\n",
      "       'satis_excel_12', 'satis_fine_12', 'cosas_imp_12', 'wouldnt_change_12',\n",
      "       'memory_12', 'ragender', 'rameduc_m', 'rafeduc_m', 'sgender_03',\n",
      "       'rjlocc_m_03', 'rjobend_reason_03', 'rrelgimp_03', 'sgender_12',\n",
      "       'rjlocc_m_12', 'rjobend_reason_12', 'rrelgimp_12', 'rrfcntx_m_12',\n",
      "       'rsocact_m_12', 'rrelgwk_12', 'a22_12', 'a33b_12', 'a34_12', 'j11_12'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List of object columns\n",
    "object_columns = train_features.select_dtypes(include=['object']).columns\n",
    "print(\"Object Columns:\\n\", object_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_03 unique values:\n",
      " [nan '1. 50–59' '3. 70–79' '2. 60–69' '0. 49 or younger' '4. 80+']\n",
      "urban_03 unique values:\n",
      " [nan '1. 100,000+' '0. <100,000']\n",
      "married_03 unique values:\n",
      " [nan '3. Widowed' '1. Married or in civil union' '4. Single'\n",
      " '2. Separated or divorced']\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in some categorical columns\n",
    "for col in ['age_03', 'urban_03', 'married_03']:\n",
    "    print(f\"{col} unique values:\\n\", train_features[col].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Categorical Columns\n",
    "\n",
    "I will use label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder instance\n",
    "label_encoders = {}\n",
    "\n",
    "# Convert categorical columns to numeric\n",
    "categorical_columns = ['age_03', 'urban_03', 'married_03', 'edu_gru_03', 'employment_03']  \n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_features[col] = le.fit_transform(train_features[col].astype(str))  # Convert to string first \n",
    "    label_encoders[col] = le  # Save the encoder for inverse transformation later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert Relevant Numeric Columns\n",
    "\n",
    "Use pd.to_numeric() for columns that should be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns that should be numeric\n",
    "numeric_columns = ['n_mar_03', 'bmi_03'] \n",
    "\n",
    "for col in numeric_columns:\n",
    "    train_features[col] = pd.to_numeric(train_features[col], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and fill or drop NaN values as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid              0\n",
      "age_03           0\n",
      "urban_03         0\n",
      "married_03       0\n",
      "n_mar_03      1054\n",
      "              ... \n",
      "a21_12        3234\n",
      "a22_12        3240\n",
      "a33b_12       3234\n",
      "a34_12        1164\n",
      "j11_12          75\n",
      "Length: 184, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(train_features.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs for numeric columns\n",
    "for col in numeric_columns:\n",
    "    train_features[col].fillna(train_features[col].mean(), inplace=True)\n",
    "\n",
    "# drop rows with NaN values for categorical columns \n",
    "train_features.dropna(subset=categorical_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid            object\n",
      "age_03          int32\n",
      "urban_03        int32\n",
      "married_03      int32\n",
      "n_mar_03      float64\n",
      "               ...   \n",
      "a21_12        float64\n",
      "a22_12         object\n",
      "a33b_12        object\n",
      "a34_12         object\n",
      "j11_12         object\n",
      "Length: 184, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#check the data types again\n",
    "print(train_features.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Object Columns:\n",
      " Index(['uid', 'n_living_child_03', 'glob_hlth_03', 'decis_famil_03', 'age_12',\n",
      "       'urban_12', 'married_12', 'edu_gru_12', 'n_living_child_12',\n",
      "       'glob_hlth_12', 'bmi_12', 'decis_famil_12', 'decis_personal_12',\n",
      "       'employment_12', 'satis_ideal_12', 'satis_excel_12', 'satis_fine_12',\n",
      "       'cosas_imp_12', 'wouldnt_change_12', 'memory_12', 'ragender',\n",
      "       'rameduc_m', 'rafeduc_m', 'sgender_03', 'rjlocc_m_03',\n",
      "       'rjobend_reason_03', 'rrelgimp_03', 'sgender_12', 'rjlocc_m_12',\n",
      "       'rjobend_reason_12', 'rrelgimp_12', 'rrfcntx_m_12', 'rsocact_m_12',\n",
      "       'rrelgwk_12', 'a22_12', 'a33b_12', 'a34_12', 'j11_12'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify remaining object columns\n",
    "object_columns = train_features.select_dtypes(include=['object']).columns\n",
    "print(\"Remaining Object Columns:\\n\", object_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert remaining categorical columns\n",
    "for col in object_columns:\n",
    "    le = LabelEncoder()\n",
    "    train_features[col] = le.fit_transform(train_features[col].astype(str))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Counts:\n",
      " migration_03       1035\n",
      "adl_dress_03       1171\n",
      "adl_walk_03        1041\n",
      "adl_bath_03        1041\n",
      "adl_eat_03         1042\n",
      "                   ... \n",
      "hinc_cap_12          89\n",
      "rinc_pension_12      89\n",
      "sinc_pension_12    1185\n",
      "a16a_12            3252\n",
      "a21_12             3234\n",
      "Length: 140, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "nan_counts = train_features.isnull().sum()\n",
    "print(\"NaN Counts:\\n\", nan_counts[nan_counts > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    " #drop specific columns that have too many missing values\n",
    "train_features.drop(columns=['a16a_12', 'a21_12'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numerical columns with mean \n",
    "numerical_cols = train_features.select_dtypes(include=['float64', 'int64', 'int32']).columns\n",
    "for col in numerical_cols:\n",
    "    train_features[col].fillna(train_features[col].mean(), inplace=True)  \n",
    "\n",
    "# Fill categorical columns with mode\n",
    "categorical_cols = train_features.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    train_features[col].fillna(train_features[col].mode()[0], inplace=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3276\n"
     ]
    }
   ],
   "source": [
    "#check the data again to ensure there are no remaining missing values\n",
    "print(train_features.isnull().sum().sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with Missing Values:\n",
      " bmi_03    3276\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count of missing values in each column\n",
    "missing_counts = train_features.isnull().sum()\n",
    "missing_columns = missing_counts[missing_counts > 0]\n",
    "\n",
    "print(\"Columns with Missing Values:\\n\", missing_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping bmi_03: Index(['uid', 'age_03', 'urban_03', 'married_03', 'n_mar_03', 'edu_gru_03',\n",
      "       'n_living_child_03', 'migration_03', 'glob_hlth_03', 'adl_dress_03',\n",
      "       ...\n",
      "       'rinc_pension_12', 'sinc_pension_12', 'rrelgimp_12', 'rrfcntx_m_12',\n",
      "       'rsocact_m_12', 'rrelgwk_12', 'a22_12', 'a33b_12', 'a34_12', 'j11_12'],\n",
      "      dtype='object', length=181)\n"
     ]
    }
   ],
   "source": [
    "# Drop the bmi_03 column\n",
    "train_features.drop(columns=['bmi_03'], inplace=True)\n",
    "\n",
    "# Check to ensure it has been dropped\n",
    "print(\"Columns after dropping bmi_03:\", train_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(train_features.isnull().sum().sum())  # Should be 0 if all missing values are handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All missing values have been handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the test features with the training features\n",
    "test_features_aligned = test_features_cleaned.reindex(columns=train_features_cleaned.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>year</th>\n",
       "      <th>composite_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aace</td>\n",
       "      <td>2021</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aanz</td>\n",
       "      <td>2021</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aape</td>\n",
       "      <td>2016</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aape</td>\n",
       "      <td>2021</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aard</td>\n",
       "      <td>2021</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  year  composite_score\n",
       "0  aace  2021              175\n",
       "1  aanz  2021              206\n",
       "2  aape  2016              161\n",
       "3  aape  2021              144\n",
       "4  aard  2021              104"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training labels\n",
    "train_labels = pd.read_csv(r\"C:\\Users\\David\\Documents\\PHASE 4 PROJECT\\PHASE 5 FINAL PROJECT\\train_labels.csv\")  \n",
    "train_labels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Check the Shape of the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (3276, 181)\n",
      "Training Labels Shape: (4343, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Features Shape:\", train_features.shape)\n",
    "print(\"Training Labels Shape:\", train_labels.shape)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Align Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid             int32\n",
      "age_03          int32\n",
      "urban_03        int32\n",
      "married_03      int32\n",
      "n_mar_03      float64\n",
      "               ...   \n",
      "rrelgwk_12      int32\n",
      "a22_12          int32\n",
      "a33b_12         int32\n",
      "a34_12          int32\n",
      "j11_12          int32\n",
      "Length: 181, dtype: object\n",
      "uid                object\n",
      "year                int64\n",
      "composite_score     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_features.dtypes)\n",
    "print(train_labels.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Check for Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect both datasets for duplicate rows that may cause discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows in features: 0\n",
      "Duplicate rows in labels: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate rows in features:\", train_features.duplicated().sum())\n",
    "print(\"Duplicate rows in labels:\", train_labels.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows in both the features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "- Visualize Data: Use visualizations to understand the distributions of key features and their relationships with the target variable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
